Ranni: Taming Text-to-Image Diffusion for Accurate Prompt Following    
Ranniï¼šé©¯æœæ–‡æœ¬åˆ°å›¾åƒçš„æ‰©æ•£ä»¥å®ç°å‡†ç¡®çš„æç¤ºè·Ÿéš   



## TODO:
æ¨¡å‹æ§åˆ¶æ•ˆæœæµ‹è¯•ï¼Œäº”å…­ä¸ªæ§åˆ¶æ–¹æ³•     
å¯¹æ¯”ä¸¤ä¸ªå…¶ä»–æ¨¡å‹    
related_work????     


## åŸºæœ¬ä¿¡æ¯ï¼š  
æœºæ„ï¼š    
Alibaba Group   |   Ant Group     

ä»“åº“ï¼š     
https://github.com/ali-vilab/Ranni   

[Submitted on 28 Nov 2023 (v1), last revised 9 Apr 2024 (this version, v3)]    
https://arxiv.org/abs/2311.17002    


This repository is based on the following codebases:

https://github.com/Stability-AI/stablediffusion   
https://github.com/lllyasviel/ControlNet/

æƒé‡ï¼š    
https://modelscope.cn/models/yutong/Ranni/files   

2024 4.8 : Ranni è¢«æ¥å—ä¸º CVPR 2024 å£å¤´è®ºæ–‡ ğŸ‰    
2024å¹´4.3ï¼šæˆ‘ä»¬å‘å¸ƒäº†Ranniçš„v1ä»£ç ã€‚    

å¾…åŠäº‹é¡¹åˆ—è¡¨ï¼š    
æ”¯æŒæ›´å¤šæ¡ä»¶ã€‚    
åŸºäºèŠå¤©çš„ç¼–è¾‘ã€‚    
å…·æœ‰ ID ä¸€è‡´æ€§çš„è¿ç»­ç”Ÿæˆã€‚     





   
## åŸç†ï¼š     
è¯¥å­˜å‚¨åº“æ˜¯ CVPR 2024 è®ºæ–‡â€œRanni: Taming Text-to-Image Diffusion for Accurate instructions Followâ€çš„å®˜æ–¹å®ç°ã€‚å®ƒåŒ…å«ä¸¤ä¸ªä¸»è¦ç»„ä»¶ï¼š1ï¼‰åŸºäºLLMçš„è§„åˆ’æ¨¡å‹ï¼Œå°†æ–‡æœ¬æŒ‡ä»¤æ˜ å°„åˆ°å›¾åƒä¸­çš„è§†è§‰å…ƒç´ ï¼Œ2ï¼‰åŸºäºæ‰©æ•£çš„ç»˜ç”»æ¨¡å‹ï¼Œåœ¨ç¬¬ä¸€é˜¶æ®µæŒ‰ç…§è§†è§‰å…ƒç´ ç»˜åˆ¶å›¾åƒã€‚å¾—ç›ŠäºLLMçš„å¼ºå¤§èƒ½åŠ›ï¼ŒRanniè·å¾—äº†æ›´å¥½çš„è¯­ä¹‰ç†è§£ã€‚ç›®å‰ï¼Œæˆ‘ä»¬å‘å¸ƒçš„æ¨¡å‹æƒé‡åŒ…æ‹¬ LoRA å¾®è°ƒçš„ LLaMa-2-7B å’Œå®Œå…¨å¾®è°ƒçš„ SDv2.1 æ¨¡å‹ã€‚     


![alt text](assets/Ranni/image.png)    
![alt text](assets/Ranni/image-1.png)     


ç°æœ‰çš„æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ‰©æ•£æ¨¡å‹é€šå¸¸éš¾ä»¥è§£é‡Šå¤æ‚çš„æç¤ºï¼Œå°¤å…¶æ˜¯é‚£äº›å…·æœ‰æ•°é‡ã€å¯¹è±¡å±æ€§ç»‘å®šå’Œå¤šä¸»é¢˜æè¿°çš„æç¤ºã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†è¯­ä¹‰é¢æ¿ä½œä¸ºå°†æ–‡æœ¬è§£ç ä¸ºå›¾åƒçš„ä¸­é—´ä»¶ï¼Œæ”¯æŒç”Ÿæˆå™¨æ›´å¥½åœ°éµå¾ªæŒ‡ä»¤ã€‚è¯¥é¢æ¿æ˜¯é€šè¿‡å€ŸåŠ©å¤§å‹è¯­è¨€æ¨¡å‹å¯¹ä»è¾“å…¥æ–‡æœ¬ä¸­è§£æå‡ºçš„è§†è§‰æ¦‚å¿µè¿›è¡Œæ’åˆ—è€Œè·å¾—çš„ï¼Œç„¶åå°†å…¶ä½œä¸ºè¯¦ç»†çš„æ§åˆ¶ä¿¡å·æ³¨å…¥åˆ°å»å™ªç½‘ç»œä¸­ä»¥è¡¥å……æ–‡æœ¬æ¡ä»¶ã€‚ä¸ºäº†ä¿ƒè¿›æ–‡æœ¬åˆ°é¢æ¿çš„å­¦ä¹ ï¼Œæˆ‘ä»¬æå‡ºäº†ç²¾å¿ƒè®¾è®¡çš„è¯­ä¹‰æ ¼å¼åŒ–åè®®ï¼Œå¹¶é…æœ‰å…¨è‡ªåŠ¨æ•°æ®å‡†å¤‡ç®¡é“ã€‚å¾—ç›Šäºè¿™æ ·çš„è®¾è®¡ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸º `Ranni çš„æ–¹æ³•èƒ½å¤Ÿå¢å¼ºé¢„è®­ç»ƒçš„ T2I ç”Ÿæˆå™¨çš„æ–‡æœ¬å¯æ§æ€§`ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œ`ç”Ÿæˆä¸­é—´ä»¶çš„å¼•å…¥å¸¦æ¥äº†æ›´ä¾¿æ·çš„äº¤äº’å½¢å¼`ï¼ˆå³ç›´æ¥è°ƒæ•´é¢æ¿ä¸­çš„å…ƒç´ æˆ–ä½¿ç”¨è¯­è¨€æŒ‡ä»¤ï¼‰ï¼Œå¹¶è¿›ä¸€æ­¥å…è®¸ç”¨æˆ·ç²¾ç»†åœ°å®šåˆ¶ä»–ä»¬çš„ç”Ÿæˆï¼Œåœ¨æ­¤åŸºç¡€ä¸Šæˆ‘ä»¬å¼€å‘äº†å®ç”¨çš„ç³»ç»Ÿå’Œå±•ç¤ºå…¶åœ¨è¿ç»­ç”Ÿæˆå’ŒåŸºäºèŠå¤©çš„ç¼–è¾‘æ–¹é¢çš„æ½œåŠ›ã€‚    

å…·æœ‰ä¸åŒçš„äº¤äº’æ–¹å¼ï¼ŒåŒ…æ‹¬ï¼ˆaï¼‰ç›´æ¥ç”Ÿæˆï¼Œå‡†ç¡®æç¤ºè·Ÿéšï¼Œ ï¼ˆbï¼‰è¿ç»­ç”Ÿæˆï¼Œé€æ­¥ç»†åŒ–ï¼Œä»¥åŠï¼ˆcï¼‰åŸºäºèŠå¤©çš„æ–‡æœ¬æŒ‡ä»¤ç”Ÿæˆã€‚   


æå‡ºäº†æ•°é‡æ„è¯†æç¤º     
![alt text](assets/Ranni/image-2.png)     
è§£å†³customnetçš„é—®é¢˜     

å¯¹ç©ºé—´å…³ç³»è¿›è¡Œæç¤ºã€‚   
å¯èƒ½è§£å†³cosxlçš„é—®é¢˜    
ä½†pixart sigmaå·²ç»è§£å†³   


å¯¹å±æ€§ç»‘å®šè¿›è¡Œäº†æç¤ºï¼ŒåŒ…æ‹¬(a)é¢œè‰²ç»‘å®šå’Œ(b)çº¹ç†ç»‘å®šã€‚ä¸ºäº†æ¸…æ¥šæ¯”è¾ƒï¼Œéšæœºç§å­è¢«å›ºå®šä»¥ä¿ç•™ä¸€è¡Œä¸­çš„ç©ºé—´æ’åˆ—ã€‚    

é¢œè‰²ç¼–è¾‘      
å¯èƒ½è§£å†³cosxlçš„é—®é¢˜    



shape editing   
![alt text](assets/Ranni/image-3.png)    

### å®è·µ

æ¨¡å‹æ¶æ„     
- base llama model   
meta-llama/Llama-2-7b-chat-hf    

- lora    
lora_weight_ele = torch.load('models/llama2_7b_lora_element.pth', map_location='cpu')   # load an empty lora here   
lora_weight_box = torch.load('models/llama2_7b_lora_bbox.pth', map_location='cpu')    

- panel2img   
model.load_state_dict(torch.load('models/ranni_sdv21_v1.pth', map_location='cpu'), strict=False)     
ddim_sampler = DDIMSampler(model)    

å®˜ç½‘ä¸‹è½½Llama-2-7b-chat   
è½¬æˆhuggingfaceæ ¼å¼     

    mv tokenizer.model llama
    mv tokenizer_checklist.chk consolidated.00.pth params.json llama/7B

    cd /root/autodl-fs/transformers
 â€‹
    python src/transformers/models/llama/convert_llama_weights_to_hf.py \
    --input_dir /root/autodl-fs/Chinese-LLaMA-Alpaca/model/llama/ \
    --model_size 7B \
    --output_dir /root/autodl-fs/Chinese-LLaMA-Alpaca/model/output

python demo_gradio.py


AssertionError: Torch not compiled with CUDA enabled   
torch 1.13    
nvcc 11.8      

pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu117

éœ€è¦é¢å¤–å®‰è£…  
basicsr   
ä½†ä¾èµ–tb-nightly    
æ¸…åæºä¸å­˜åœ¨tb-nightly    
pip install tb-nightly -i https://mirrors.aliyun.com/pypi/simple    



#### å‚æ•°
    control_max_t = gr.Slider(label="Control start", minimum=0, maximum=1000, value=1000, step=0)
    control_min_t = gr.Slider(label="Control stop", minimum=0, maximum=1000, value=600, step=0)
    panel_control_scale = gr.Slider(label="Control scale", minimum=0, maximum=5.0, value=0.6, step=0.1)

å‡½æ•°   

    run_button.click(
        fn=stage1_process, 
        inputs=[prompt, seed], 
        outputs=[box_answer, mid_result_gallery])

    run_button2.click(
        fn=stage2_process, 
        inputs=[box_answer, prompt, postfix, seed, n_prompt, guide_scale, steps, control_max_t, control_min_t, panel_control_scale, with_memory], 
        outputs=[result_gallery])

    refresh_button.click(
        fn=refresh_condition,
        inputs=[box_answer, postfix],
        outputs=[mid_result_gallery]
        )

### Box Answerå¦‚ä½•ç”Ÿæˆï¼Ÿ



### æŠ¥é”™

with memory 

    Traceback (most recent call last):
    File "/root/miniconda3/envs/ranni/lib/python3.10/site-packages/gradio/queueing.py", line 388, in call_prediction
        output = await route_utils.call_process_api(
    File "/root/miniconda3/envs/ranni/lib/python3.10/site-packages/gradio/route_utils.py", line 219, in call_process_api
        output = await app.get_blocks().process_api(
    File "/root/miniconda3/envs/ranni/lib/python3.10/site-packages/gradio/blocks.py", line 1437, in process_api
        result = await self.call_function(
    File "/root/miniconda3/envs/ranni/lib/python3.10/site-packages/gradio/blocks.py", line 1109, in call_function
        prediction = await anyio.to_thread.run_sync(
    File "/root/miniconda3/envs/ranni/lib/python3.10/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
    File "/root/miniconda3/envs/ranni/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 2144, in run_sync_in_worker_thread
        return await future
    File "/root/miniconda3/envs/ranni/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 851, in run
        result = context.run(func, *args)
    File "/root/miniconda3/envs/ranni/lib/python3.10/site-packages/gradio/utils.py", line 641, in wrapper
        response = f(*args, **kwargs)
    File "/home/WujieAITeam/private/lujunda/newtest/Ranni/demo_gradio.py", line 232, in stage2_process
        edit_mask=resized_edit_mask if with_memory else None, edit_intermediates=intermediates)
    UnboundLocalError: local variable 'resized_edit_mask' referenced before assignment




 
## è¯­è¨€æ¨¡å‹ llama-2-7b-chat



### è¯­è¨€æ¨¡å‹è®­ç»ƒæ–¹å¼
AIæ¨¡å‹çš„è®­ç»ƒè®­ç»ƒè¿‡ç¨‹åˆ†ä¸ºå¦‚ä¸‹ä¸‰ä¸ªé˜¶æ®µ

ç¬¬ä¸€ä¸ªé˜¶æ®µå«åšæ— ç›‘ç£å­¦ä¹ ï¼ˆPreTrainingï¼‰ï¼Œå°±æ˜¯è¾“å…¥å¤§é‡çš„æ–‡æœ¬è¯­æ–™è®©GPTè‡ªå·±å¯»æ‰¾è¯­è¨€çš„è§„å¾‹ï¼Œ è¿™æ ·ä¸€ä¸ªå·¨å¤§çš„è¯å‘é‡ç©ºé—´å°±å½¢æˆäº†ï¼Œä½†æ˜¯è¯è¯´çš„æ¼‚äº®å¹¶ä¸ä¸€å®šæ­£ç¡®ã€‚

ç¬¬äºŒä¸ªé˜¶æ®µå«åšç›‘ç£å­¦ä¹ (Supervised Fine-Tuning,ä¹Ÿå«å¾®è°ƒ)ï¼Œå°±æ˜¯äººå·¥æ ‡æ³¨ä¸€äº›è¯­æ–™ï¼Œæ•™ä¼šGPTä»€ ä¹ˆè¯¥è¯´ï¼Œä»€ä¹ˆä¸è¯¥è¯´ã€‚ï¼ˆè®­ç»ƒæ•°æ®é›†ï¼‰

ç¬¬ä¸‰ä¸ªé˜¶æ®µå«åšå¼ºåŒ–å­¦ä¹ ï¼ˆRMï¼Œä¹Ÿå«å¥–åŠ±æ¨¡å‹è®­ç»ƒï¼‰ï¼Œå°±æ˜¯ç»™GPTçš„å›ç­”è¿›è¡Œæ‰“åˆ†ï¼Œå‘Šè¯‰ä»–åœ¨ä»– çš„ä¸€ä¼—å›ç­”ä¸­ï¼Œå“ªäº›å›ç­”æ›´å¥½ã€‚ï¼ˆéªŒè¯æ•°æ®é›†ï¼‰

ç¬¬ä¸€ä¸ªé˜¶æ®µï¼ˆæ— ç›‘ç£å­¦ä¹ ï¼‰ï¼Œåˆåˆ†ä¸ºäº†åº•åº§æ¨¡å‹é¢„è®­ç»ƒï¼ŒåŠå¢é‡é¢„è®­ç»ƒï¼Œå®ƒä»¬éƒ½å±äºæ— ç›‘ç£å­¦ä¹ ï¼ŒåŸºåº§æ¨¡å‹é¢„è®­ç»ƒå¯ä»¥æŸ¥çœ‹ä¸Šç¯‡æ–‡ç« ï¼šä½¿ç”¨æ•°æ®é¢„è®­ç»ƒä¸€ä¸ªAIè¯­è¨€æ¨¡å‹

æœ¬æ–‡ä¸»è¦æ¥èŠèŠæœ‰äº†ä¸€ä¸ªåº•åº§æ¨¡å‹ä¹‹åï¼Œå¦‚ä½•ç»§ç»­ä½¿ç”¨å¤§é‡æ–‡æœ¬è¿›è¡Œå¢é‡é¢„è®­ç»ƒã€‚


#### å¢é‡é¢„è®­ç»ƒ

å¢é‡é¢„è®­ç»ƒä¹Ÿå«é¢†åŸŸè‡ªé€‚åº”é¢„è®­ç»ƒï¼ˆdomain-adapter pretrainingï¼‰ï¼Œå³åœ¨æ‰€å±é¢†åŸŸæ•°æ®ä¸Šç»§ç»­é¢„è®­ç»ƒã€‚

ä¸»è¦é—®é¢˜æ˜¯åœ¨å¢é‡é¢„è®­ç»ƒåå¯èƒ½å‘ç”Ÿç¾éš¾æ€§é—å¿˜ã€‚

é¿å…ç¾éš¾æ€§é—å¿˜ä¸»è¦ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢å…¥æ‰‹ï¼š

1 é¢†åŸŸç›¸å…³æ€§

å¢é‡æ•°æ®ä¸æ‰€é€‰åŸºåº§æ¨¡å‹çš„åŸå§‹è®­ç»ƒæ•°æ®å°½é‡ä¸€å®šçš„ç›¸å…³æ€§ã€‚

2 æ–°æ•°æ®åˆ†å¸ƒä¸åŸå§‹æ•°æ®å°½é‡ç›¸ä¼¼

é¢†åŸŸæ•°æ®å’Œé€šç”¨æ•°æ®çš„æ¯”ç‡ï¼Œç»“åˆå…·ä½“æ•°æ®ï¼š10%ï¼Œ15%ï¼Œ20%çš„éƒ½æœ‰ã€‚

æ–¹æ¡ˆä¹‹ä¸€æ˜¯ï¼šè®©æ— ç›‘ç£æ•°æ®å’ŒæŒ‡ä»¤æ•°æ®æ··åˆï¼Œåˆå¹¶å¢é‡é¢„è®­ç»ƒå’Œå¾®è°ƒä¸¤ä¸ªé˜¶æ®µã€‚

3 é™ä½å­¦ä¹ ç‡

å¢é‡é¢„è®­ç»ƒ2e-5ï¼›æŒ‡ä»¤å¾®è°ƒéœ€è¦æ›´ä½1e-6ï¼›ä½†æ˜¯å¾—å¤šè·‘å‡ è½®ä¸ç„¶å­¦ä¸åˆ°é¢†åŸŸçŸ¥è¯†

4 è¿›è¡Œwarm upï¼Œ

åœ¨ç¬¬ä¸€è½®è®­ç»ƒçš„æ—¶å€™ï¼Œæ¯ä¸ªæ•°æ®ç‚¹å¯¹æ¨¡å‹æ¥è¯´éƒ½æ˜¯æ–°çš„ï¼Œæ¨¡å‹ä¼šå¾ˆå¿«åœ°è¿›è¡Œæ•°æ®åˆ†å¸ƒä¿®æ­£ï¼Œå¦‚æœè¿™æ—¶å€™å­¦ä¹ ç‡å°±å¾ˆå¤§ï¼Œææœ‰å¯èƒ½å¯¼è‡´å¼€å§‹çš„æ—¶å€™å°±å¯¹è¯¥æ•°æ®â€œè¿‡æ‹Ÿåˆâ€ï¼Œåé¢è¦é€šè¿‡å¤šè½®è®­ç»ƒæ‰èƒ½æ‹‰å›æ¥ï¼Œæµªè´¹æ—¶é—´ã€‚å½“è®­ç»ƒäº†ä¸€æ®µæ—¶é—´ï¼ˆæ¯”å¦‚ä¸¤è½®ã€ä¸‰è½®ï¼‰åï¼Œæ¨¡å‹å·²ç»å¯¹æ¯ä¸ªæ•°æ®ç‚¹çœ‹è¿‡å‡ éäº†ï¼Œæˆ–è€…è¯´å¯¹å½“å‰çš„batchè€Œè¨€æœ‰äº†ä¸€äº›æ­£ç¡®çš„å…ˆéªŒï¼Œè¾ƒå¤§çš„å­¦ä¹ ç‡å°±ä¸é‚£ä¹ˆå®¹æ˜“ä¼šä½¿æ¨¡å‹å­¦åï¼Œæ‰€ä»¥å¯ä»¥é€‚å½“è°ƒå¤§å­¦ä¹ ç‡ã€‚è¿™ä¸ªè¿‡ç¨‹å°±å¯ä»¥çœ‹åšæ˜¯warmupã€‚é‚£ä¹ˆä¸ºä»€ä¹ˆä¹‹åè¿˜è¦decayå‘¢ï¼Ÿå½“æ¨¡å‹è®­åˆ°ä¸€å®šé˜¶æ®µåï¼ˆæ¯”å¦‚åä¸ªepochï¼‰ï¼Œæ¨¡å‹çš„åˆ†å¸ƒå°±å·²ç»æ¯”è¾ƒå›ºå®šäº†ï¼Œæˆ–è€…è¯´èƒ½å­¦åˆ°çš„æ–°ä¸œè¥¿å°±æ¯”è¾ƒå°‘äº†ã€‚å¦‚æœè¿˜æ²¿ç”¨è¾ƒå¤§çš„å­¦ä¹ ç‡ï¼Œå°±ä¼šç ´åè¿™ç§ç¨³å®šæ€§ï¼Œç”¨æˆ‘ä»¬é€šå¸¸çš„è¯è¯´ï¼Œå°±æ˜¯å·²ç»æ¥è¿‘lossçš„local optimaläº†ï¼Œä¸ºäº†é è¿‘è¿™ä¸ªpointï¼Œæˆ‘ä»¬å°±è¦æ…¢æ…¢æ¥ã€‚

5 å¯¹æ–°ä»»åŠ¡ä¸­å‚æ•°çš„å˜åŒ–æ–½åŠ æƒ©ç½š

6 çŸ¥è¯†è’¸é¦ï¼ˆKDï¼‰ï¼Œä½¿å¾®è°ƒæ¨¡å‹çš„é¢„æµ‹ç»“æœæ¥è¿‘æ—§æ¨¡å‹çš„é¢„æµ‹ç»“æœã€‚


æœ¬æ–‡ä¸»è¦æ¥èŠèŠæœ‰äº†ä¸€ä¸ªåº•åº§æ¨¡å‹ä¹‹åï¼Œå¦‚ä½•ç»§ç»­ä½¿ç”¨å¤§é‡æ–‡æœ¬è¿›è¡Œå¢é‡é¢„è®­ç»ƒã€‚   
##### åˆå¹¶æ¨¡å‹
1ã€llamaæ¨¡å‹è½¬æ¢(pytorchæ ¼å¼è½¬æ¢ä¸ºHuggingFaceæ ¼å¼)

ç”±äºä½¿ç”¨çš„åº•åº§æ¨¡å‹æ˜¯llamaï¼Œå®˜æ–¹å…¬å¸ƒçš„æ˜¯PyTorchç‰ˆæœ¬ï¼Œä¸ºäº†æ–¹ä¾¿åç»­ä½¿ç”¨ï¼Œéœ€è½¬æ¢ä¸ºHuggingFaceæ ¼å¼

2.åˆå¹¶æ¨¡å‹   
ç”±äºåŸå§‹llamaæ¨¡å‹å¯¹ä¸­æ–‡çš„æ”¯æŒä¸æ˜¯å¾ˆä¼˜ç§€ï¼Œæ‰€ä»¥éœ€åˆå¹¶ä¸€ä¸ªChinese-LLaMA-Plus-7Bæ¨¡å‹å’Œchinese_llama_plus_lora_7bæ¨¡å‹â€‹


2.1ã€ä¸‹è½½Chinese-LLaMA-Plus-7Bæ¨¡å‹    
 unzip chinese_llama_plus_lora_7b.zip chinese_llama_plus_lora_7b

2.2ã€ä¸‹è½½chinese_alpaca_plus_lora_7bæ¨¡å‹   
 unzip chinese_alpaca_plus_lora_7b.zip chinese_alpaca_plus_lora_7b

 è¿™æ˜¯æŒ‚ä¸¤ä¸ªlora

    python scripts/merge_llama_with_chinese_lora.py \
    --base_model /root/autodl-fs/Chinese-LLaMA-Alpaca/model/output \
    --lora_model /root/autodl-fs/llama_7b/chinese_llama_plus_lora_7b,/root/autodl-fs/llama_7b/chinese_alpaca_plus_lora_7b \
    --output_type huggingface \
    --output_dir /root/autodl-fs/Chinese-LLaMA-Alpaca/model/firstmergemodels


4.2ã€è®­ç»ƒåæ–‡ä»¶æ•´ç†

è®­ç»ƒåçš„LoRAæƒé‡å’Œé…ç½®å­˜æ”¾äº

/root/autodl-fs/Chinese-LLaMA-Alpaca/model/pt_output/pt_lora_modelï¼Œå¯ç”¨äºåç»­çš„åˆå¹¶æµç¨‹ã€‚


åˆå¹¶æ¨¡å‹

    python scripts/merge_llama_with_chinese_lora.py \
    --base_model /root/autodl-fs/Chinese-LLaMA-Alpaca/model/firstmergemodels \
    --lora_model /root/autodl-fs/Chinese-LLaMA-Alpaca/model/pt_output/pt_lora_model/lora_model \
    --output_type huggingface \
    --output_dir /root/autodl-fs/Chinese-LLaMA-Alpaca/model/ptmerge_model



## å±€é™
after having tried many times with different prompts and seeds, most of results coming out are not desirable,
generally speaking they still got issues with colours and numbers, I feel like the default demo examples are kinda of cherry picking, hopefully they can release the version they used in the original paper

The current released version is based on the pure SDv2.1 and it not quite stable especially for local attribute binding. We improve it by ignoring the global <eos> token for better local control, but it is still worse than the paper version. The paper version is a larger private 3B diffusion model with better image quality and local sensibility (with different text conditioning). We are still working to develop and release better version of the panel-to-image model.   



# ç»“å°¾
