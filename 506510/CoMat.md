ğŸ’«CoMat: Aligning Text-to-Image Diffusion Model with Image-to-Text Concept Matching    
ğŸ’«CoMatï¼šå°†æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸å›¾åƒåˆ°æ–‡æœ¬æ¦‚å¿µåŒ¹é…å¯¹é½



# è®ºæ–‡ä¿¡æ¯ï¼š
[Submitted on 4 Apr 2024]
CoMat: Aligning Text-to-Image Diffusion Model with Image-to-Text Concept Matching

Dongzhi Jiang1,2, Guanglu Song2, Xiaoshi Wu1, Renrui Zhang1,3, Dazhong Shen3, Zhuofan Zong2,
Yu Liu2, Hongsheng Li1    
1CUHK MMLab,    
2SenseTime Research, 3Shanghai AI Laboratory    
æ¸¯ä¸­æ–‡    

[2024.04.30] ğŸ”¥ We release the training code of CoMat.

[2024.04.05] ğŸš€ We release our paper on arXiv.

æˆ‘ä»¬æå‡ºäº†ğŸ’«CoMatï¼Œä¸€ç§å…·æœ‰å›¾åƒåˆ°æ–‡æœ¬æ¦‚å¿µåŒ¹é…æœºåˆ¶çš„ç«¯åˆ°ç«¯æ‰©æ•£æ¨¡å‹å¾®è°ƒç­–ç•¥ã€‚æˆ‘ä»¬åˆ©ç”¨å›¾åƒå­—å¹•æ¨¡å‹æ¥æµ‹é‡å›¾åƒåˆ°æ–‡æœ¬çš„å¯¹é½æƒ…å†µï¼Œå¹¶æŒ‡å¯¼æ‰©æ•£æ¨¡å‹é‡æ–°è®¿é—®è¢«å¿½ç•¥çš„æ ‡è®°ã€‚

è®­ç»ƒ   
æˆ‘ä»¬ç›®å‰æ”¯æŒSD1.5å’ŒSDXLã€‚


https://github.com/CaraJ7/CoMat





# åŸç†
æ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆé¢†åŸŸå–å¾—äº†å·¨å¤§æˆåŠŸã€‚ç„¶è€Œï¼Œå‡è½»æ–‡æœ¬æç¤ºå’Œå›¾åƒä¹‹é—´çš„é”™ä½ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æœªå¯¹å‡†èƒŒåçš„æ ¹æœ¬åŸå› å°šæœªå¾—åˆ°å¹¿æ³›è°ƒæŸ¥ã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°è¿™ç§`é”™ä½æ˜¯ç”±äºä»¤ç‰Œæ³¨æ„åŠ›æ¿€æ´»ä¸è¶³`å¼•èµ·çš„ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å°†è¿™ç§ç°è±¡å½’å› äºæ‰©æ•£æ¨¡å‹çš„æ¡ä»¶åˆ©ç”¨ä¸è¶³ï¼Œè¿™æ˜¯ç”±å…¶è®­ç»ƒèŒƒå¼é€ æˆçš„ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº† CoMatï¼Œä¸€ç§å…·æœ‰å›¾åƒåˆ°æ–‡æœ¬æ¦‚å¿µåŒ¹é…æœºåˆ¶çš„ç«¯åˆ°ç«¯æ‰©æ•£æ¨¡å‹å¾®è°ƒç­–ç•¥ã€‚æˆ‘ä»¬`åˆ©ç”¨å›¾åƒå­—å¹•æ¨¡å‹æ¥æµ‹é‡å›¾åƒåˆ°æ–‡æœ¬çš„å¯¹é½æƒ…å†µï¼Œå¹¶æŒ‡å¯¼æ‰©æ•£æ¨¡å‹é‡æ–°è®¿é—®è¢«å¿½ç•¥çš„æ ‡è®°`ã€‚è¿˜æå‡ºäº†ä¸€ç§`æ–°é¢–çš„å±æ€§é›†ä¸­æ¨¡å—æ¥è§£å†³å±æ€§ç»‘å®šé—®é¢˜`ã€‚åœ¨æ²¡æœ‰ä»»ä½•å›¾åƒæˆ–äººç±»åå¥½æ•°æ®çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬`ä»…ä½¿ç”¨ 20K æ–‡æœ¬æç¤º`æ¥å¾®è°ƒ SDXL ä»¥è·å¾— CoMat-SDXLã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒCoMat-SDXL åœ¨ä¸¤ä¸ªæ–‡æœ¬åˆ°å›¾åƒå¯¹é½åŸºå‡†æµ‹è¯•ä¸­æ˜¾ç€ä¼˜äºåŸºçº¿æ¨¡å‹ SDXLï¼Œå¹¶å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚


The text-to-image diffusion model (T2I-Model) first generates an image according to the text prompt. Then the image is sent to the Concept Matching module, Attribute Concentration module, and Fidelity Preservation module to compute the loss for fine-tuning the online T2I-Model.

![alt text](assets/CoMat/image-2.png)

å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åˆ©ç”¨å›¾åƒå­—å¹•æ¨¡å‹æ¥ç›‘ç£æ‰©æ•£æ¨¡å‹ï¼Œä»¥å……åˆ†å…³æ³¨æ¦‚å¿µåŒ¹é…æ¨¡å—ä¸­æ–‡æœ¬æç¤ºä¸­çš„æ¯ä¸ªæ¦‚å¿µã€‚åœ¨å±æ€§é›†ä¸­æ¨¡å—ä¸­ï¼Œæˆ‘ä»¬ä¿ƒè¿›æ¯ä¸ªå®ä½“çš„åè¯å’Œå±æ€§çš„æ³¨æ„åŠ›å›¾çš„ä¸€è‡´æ€§ã€‚æœ€åï¼Œåœ¨ä¿çœŸåº¦ä¿æŒæ¨¡å—ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„å¯¹æŠ—æ€§æŸå¤±æ¥ä¿æŒåœ¨çº¿å¾®è°ƒæ¨¡å‹çš„ç”Ÿæˆè´¨é‡ã€‚

Specifically, we leverage an image captioning model to supervise the diffusion model to sufficiently attend to each concept in the text prompt in the Concept Matching module. In the Attribute Concentration module, we promote the consistency of the attention map of each entity's noun and attributes. Finally, in the Fidelity Preservation module, we introduce a novel adversarial loss to conserve the generation quality of the online fine-tuning model.




# æ•ˆæœ 
![alt text](assets/CoMat/image.png)

![alt text](assets/CoMat/image-1.png)








#  ç»“å°¾