Impose Constant Light




# è®ºæ–‡ä¿¡æ¯ï¼š
controlnetä½œè€…



IC-Light æ˜¯ä¸€ä¸ªæ§åˆ¶å›¾åƒç…§æ˜çš„é¡¹ç›®ã€‚

â€œIC-Lightâ€è¿™ä¸ªåç§°ä»£è¡¨â€œImpose Constant Lightâ€ï¼ˆæˆ‘ä»¬å°†åœ¨æœ¬é¡µæœ«å°¾ç®€è¦æè¿°è¿™ä¸€ç‚¹ï¼‰ã€‚

ç›®å‰ï¼Œæˆ‘ä»¬å‘å¸ƒäº†ä¸¤ç§ç±»å‹çš„æ¨¡å‹ï¼šæ–‡æœ¬æ¡ä»¶é‡æ–°å…‰ç…§æ¨¡å‹å’ŒèƒŒæ™¯æ¡ä»¶æ¨¡å‹ã€‚ä¸¤ç§ç±»å‹éƒ½å°†å‰æ™¯å›¾åƒä½œä¸ºè¾“å…¥ã€‚



Related Work

Also read ...

Total Relighting: Learning to Relight Portraits for Background Replacement

Relightful Harmonization: Lighting-aware Portrait Background Replacement

SwitchLight: Co-design of Physics-driven Architecture and Pre-training Framework for Human Portrait Relighting
About

å‹å·æ³¨é‡Š 

iclight_sd15_fc.safetensors - é»˜è®¤çš„é‡æ–°ç…§æ˜æ¨¡å‹ï¼Œä»¥æ–‡æœ¬å’Œå‰æ™¯ä¸ºæ¡ä»¶ã€‚æ‚¨å¯ä»¥ä½¿ç”¨åˆå§‹æ½œä¼æ¥å½±å“é‡æ–°ç…§æ˜ã€‚

iclight_sd15_fcon.safetensors - ä¸â€œiclight_sd15_fc.safetensorsâ€ç›¸åŒï¼Œä½†ä½¿ç”¨åç§»å™ªå£°è¿›è¡Œè®­ç»ƒã€‚è¯·æ³¨æ„ï¼Œåœ¨ç”¨æˆ·ç ”ç©¶ä¸­ï¼Œé»˜è®¤çš„â€œiclight_sd15_fc.safetensorsâ€ç¨å¾®ä¼˜äºæ­¤æ¨¡å‹ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆé»˜è®¤æ¨¡å‹æ˜¯æ²¡æœ‰åç§»å™ªå£°çš„æ¨¡å‹çš„åŸå› ã€‚    
Same as "iclight_sd15_fc.safetensors" but trained with offset noise. Note that the default "iclight_sd15_fc.safetensors" outperform this model slightly in a user study. And this is the reason why the default model is the model without offset noise.      
å†å²ç»éªŒå¯ä»¥å¾—åˆ°æ›´çº¯çš„å›¾ç‰‡é¢œè‰²

iclight_sd15_fbc.safetensors - ä»¥æ–‡æœ¬ã€å‰æ™¯å’ŒèƒŒæ™¯ä¸ºæ¡ä»¶çš„é‡æ–°ç…§æ˜æ¨¡å‹ã€‚





[ç«]5.13æ›´æ–°   
Currently ComfyUI and Forge versions are available:     
â— https://github.com/huchenlei/ComfyUI-IC-Light-Native   
â— https://github.com/huchenlei/sd-forge-ic-light    
â— https://github.com/kijai/ComfyUI-IC-Light   
I will work on A1111 extension soon.    







# åŸç†

æ¢èƒŒæ™¯ï¼Œæ¢ç¯å…‰æ–¹å‘ï¼ˆå››ä¸ªï¼šä¸Šä¸‹å·¦å³ï¼‰     
æ§åˆ¶å…‰ç…§æŸ”å’Œä¸å¼ºçƒˆç¨‹åº¦ï¼Œå…‰ç§     


## Text-Conditioned Model   
è¾“å…¥ï¼šæä¾›äººç‰©å›¾ç‰‡ï¼ˆä¼šè¢«è‡ªåŠ¨æå–æœªå‰æ™¯å†è¾“å…¥æ¨¡å‹ï¼‰ï¼Œåˆ å»èƒŒæ™¯è·å–å‰æ™¯å›¾

(Note that the "Lighting Preference" are just initial latents - eg., if the Lighting Preference is "Left" then initial latent is left white right black.)      

Prompt: beautiful woman, detailed face, warm atmosphere, at home, bedroom

Lighting Preference: Left

## Background-Conditioned Model     
è¾“å…¥ï¼šæä¾›äººç‰©å›¾ç‰‡ï¼Œçº¯èƒŒæ™¯å›¾    

èƒŒæ™¯å›¾å¯ä»¥flip     


![alt text](assets/IC-Light/image-2.png)



æ¥è‡ªâ€œå¤–è§‚æ··åˆâ€å’Œâ€œå…‰æºæ··åˆâ€çš„ä¸¤ä¸ªå›¾åƒæ˜¯ä¸€è‡´çš„ï¼ˆç†æƒ³æƒ…å†µä¸‹ï¼Œåœ¨ HDR ç©ºé—´ä¸­æ•°å­¦ä¸Šæ˜¯ç­‰æ•ˆçš„ï¼‰ã€‚

åœ¨è®­ç»ƒé‡æ–°ç…§æ˜æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬å¼ºåŠ äº†è¿™ç§ä¸€è‡´æ€§ï¼ˆåœ¨æ½œåœ¨ç©ºé—´ä¸­ä½¿ç”¨ MLPï¼‰ã€‚

å› æ­¤ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿäº§ç”Ÿé«˜åº¦ä¸€è‡´çš„é‡æ–°å…‰ç…§ -å¦‚æ­¤ä¸€è‡´ï¼Œç”šè‡³å¯ä»¥å°†ä¸åŒçš„é‡æ–°å…‰ç…§åˆå¹¶ä¸ºæ³•çº¿è´´å›¾ï¼å°½ç®¡äº‹å®ä¸Šè¿™äº›æ¨¡å‹æ˜¯æ½œåœ¨æ‰©æ•£çš„ã€‚
As a result, the model is able to produce highly consistent relight - so consistent that different relightings can even be merged as normal maps! Despite the fact that the models are latent diffusion.

ä»æ‰©æ•£æ¨¡å‹çš„è§’åº¦å®ç°æ‰“å…‰ï¼Œå‡ åå¹´å‰çš„æŠ€æœ¯å¤ç°


![alt text](assets/IC-Light/image-4.png)
ä»å·¦åˆ°å³ä¾æ¬¡æ˜¯è¾“å…¥ã€æ¨¡å‹è¾“å‡ºã€é‡æ–°ç…§æ˜ã€åˆ†å‰²çš„é˜´å½±å›¾åƒå’Œåˆå¹¶çš„æ³•çº¿è´´å›¾ã€‚è¯·æ³¨æ„ï¼Œè¯¥æ¨¡å‹æœªä½¿ç”¨ä»»ä½•æ³•çº¿è´´å›¾æ•°æ®è¿›è¡Œè®­ç»ƒã€‚è¿™ä¸ªæ­£å¸¸çš„ä¼°è®¡æ¥è‡ªäºé‡æ–°ç‚¹äº®çš„ä¸€è‡´æ€§ã€‚










## æ–½åŠ ä¸€è‡´çš„å…‰
åœ¨ HDR ç©ºé—´ä¸­ï¼Œç…§æ˜å…·æœ‰æ‰€æœ‰å…‰ä¼ è¾“éƒ½æ˜¯ç‹¬ç«‹çš„å±æ€§ã€‚     
illumination has a property that all light transports are independent.



å› æ­¤ï¼Œä¸åŒå…‰æºçš„å¤–è§‚æ··åˆç›¸å½“äºæ··åˆå…‰æºçš„å¤–è§‚ï¼š   
the blending of appearances of different light sources is equivalent to the appearance with mixed light sources:
![alt text](assets/IC-Light/image-3.png)



# ä»£ç 

## å†…éƒ¨
ç®—æ³•æµç¨‹ï¼šè¾“å…¥å‚è€ƒå›¾ -> RMBG-1.4 å‰æ™¯æå– -> i2i -> i2i

æ‰“å…‰æ–¹å‘åŸç†
the "Lighting Preference" are just initial latents - eg., if the Lighting Preference is "Left" then initial latent is left white right black.

æ¨¡å‹ç»†èŠ‚
we release two types of models: text-conditioned relighting model and background-conditioned model. Both types take foreground images as inputs.
ä½œè€…ç»™äº†ä¸¤ç§unetæ¨¡å‹ï¼Œä½¿ç”¨æ—¶åˆ†åˆ«èåˆåˆ°åº•æ¨¡ä¸­
sd_merged = {k: sd_origin[k] + sd_offset[k] for k in sd_origin.keys()}
unet.load_state_dict(sd_merged, strict=True)
unetæ¨¡å‹ç»“æ„è½»å¾®ä¿®æ”¹


å…‰æ–¹å‘åˆå§‹latent çº¿æ€§å…³ç³»

    if bg_source == BGSource.NONE:
            pass
        elif bg_source == BGSource.LEFT:
            gradient = np.linspace(255, 0, image_width)
            image = np.tile(gradient, (image_height, 1))
            input_bg = np.stack((image,) * 3, axis=-1).astype(np.uint8)
        elif bg_source == BGSource.RIGHT:
            gradient = np.linspace(0, 255, image_width)
            image = np.tile(gradient, (image_height, 1))
            input_bg = np.stack((image,) * 3, axis=-1).astype(np.uint8)
        elif bg_source == BGSource.TOP:
            gradient = np.linspace(255, 0, image_height)[:, None]
            image = np.tile(gradient, (1, image_width))
            input_bg = np.stack((image,) * 3, axis=-1).astype(np.uint8)
        elif bg_source == BGSource.BOTTOM:
            gradient = np.linspace(0, 255, image_height)[:, None]
            image = np.tile(gradient, (1, image_width))
            input_bg = np.stack((image,) * 3, axis=-1).astype(np.uint8)
        else:
            raise 'Wrong initial latent!'




conds, unconds = encode_prompt_pair(positive_prompt=prompt + ', ' + a_prompt, negative_prompt=n_prompt)


    fg = resize_and_center_crop(input_fg, image_width, image_height)

    concat_conds = numpy2pytorch([fg]).to(device=vae.device, dtype=vae.dtype)
    concat_conds = vae.encode(concat_conds).latent_dist.mode() * vae.config.scaling_factor


ç¬¬ä¸€é˜¶æ®µ i2i ï¼šLighting Preference latent ä½œä¸ºåˆå§‹åŒ– latent    
ç¬¬äºŒé˜¶æ®µ i2i ï¼šæ ¹æ®Highres scaleæ”¾å¤§

ç¬¬ä¸€é˜¶æ®µ

    bg = resize_and_center_crop(input_bg, image_width, image_height)
    bg_latent = numpy2pytorch([bg]).to(device=vae.device, dtype=vae.dtype)
    bg_latent = vae.encode(bg_latent).latent_dist.mode() * vae.config.scaling_factor
    latents = i2i_pipe(
        image=bg_latent,
        strength=lowres_denoise,
        prompt_embeds=conds,
        negative_prompt_embeds=unconds,
        width=image_width,
        height=image_height,
        num_inference_steps=int(round(steps / lowres_denoise)),
        æ•´ä¸ªè¡¨è¾¾å¼çš„ä½œç”¨å°±æ˜¯å¯¹ steps é™¤ä»¥ lowres_denoise çš„ç»“æœè¿›è¡Œå››èˆäº”å…¥ï¼Œè¿”å›æœ€æ¥è¿‘çš„æ•´æ•°å€¼ã€‚
        num_images_per_prompt=num_samples,
        generator=rng,
        output_type='latent',
        guidance_scale=cfg,
        cross_attention_kwargs={'concat_conds': concat_conds},
        è¿™ä¸ªåœ°æ–¹ç±»ä¼¼controlnet     
    ).images.to(vae.dtype) / vae.config.scaling_factor

    pixels = vae.decode(latents).sample
    pixels = pytorch2numpy(pixels)
    pixels = [resize_without_crop(
        image=p,
        target_width=int(round(image_width * highres_scale / 64.0) * 64),
        target_height=int(round(image_height * highres_scale / 64.0) * 64))
    for p in pixels]
    pixelç©ºé—´è¿›è¡Œå›¾ç‰‡æ”¾å¤§ï¼Œresize    


    pixels = numpy2pytorch(pixels).to(device=vae.device, dtype=vae.dtype)
    latents = vae.encode(pixels).latent_dist.mode() * vae.config.scaling_factor
    latents = latents.to(device=unet.device, dtype=unet.dtype)

    image_height, image_width = latents.shape[2] * 8, latents.shape[3] * 8 
    è¿™ä¸ªæ“ä½œä¸æ˜ç™½      

    fg = resize_and_center_crop(input_fg, image_width, image_height)
    concat_conds = numpy2pytorch([fg]).to(device=vae.device, dtype=vae.dtype)
    concat_conds = vae.encode(concat_conds).latent_dist.mode() * vae.config.scaling_factor

    æ²¡æœ‰å¿…è¦åšä¸¤æ¬¡



ç¬¬äºŒé˜¶æ®µ

    latents = i2i_pipe(
        image=latents,
        strength=highres_denoise,
        prompt_embeds=conds,
        negative_prompt_embeds=unconds,
        width=image_width,
        height=image_height,
        num_inference_steps=int(round(steps / highres_denoise)),
        num_images_per_prompt=num_samples,
        generator=rng,
        output_type='latent',
        guidance_scale=cfg,
        cross_attention_kwargs={'concat_conds': concat_conds},
    ).images.to(vae.dtype) / vae.config.scaling_factor

    pixels = vae.decode(latents).sample

















## gradioè¿è¡Œé”™è¯¯è§£å†³

### ç¬¬ä¸€ä¸ªé”™è¯¯

    File "/root/miniconda3/envs/iclight/lib/python3.10/site-packages/torch/cuda/__init__.py", line 293, in _lazy_init
        torch._C._cuda_init()
    RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.

pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121    

torch                     2.3.0+cu121        
torchvision               0.18.0+cu121

ä¸åŒ¹é…        
nvcc 11.8         
nvidia-smi CUDA 11.4        



pip install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cu118


é™ä½torchç‰ˆæœ¬å¯ä»¥äº†

### ç¬¬äºŒæ¬¡é”™è¯¯
æ¨ç†æ—¶å€™ã€‚    
Segmentation fault (core dumped)     
åº”è¯¥æ˜¯c++ cå±‚é¢çš„é”™è¯¯ï¼Œç©ºæŒ‡é’ˆï¼Œå †æ ˆæº¢å‡º,tensoré—®é¢˜ç­‰      

ä»¥å‰åœ¨jetsonä¸Šä½¿ç”¨c++ç¨‹åºä¹Ÿé‡åˆ°è¿‡    

æ¢æœºå™¨é‡è£…

Nvidia-smi CUDA Version: 12.2     
Nvcc 11.8   
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121     
å¯ä»¥äº†   






## comfyui è¿è¡Œ

Chilloutmix-Ni-pruned-fp16-fix.safetensorsåº•æ¨¡     
ç”Ÿå›¾å¾ˆèŠ±     

Photon_v1_fp16.safetensorsç¬¬ä¸€æ¬¡ä¸‹è½½ä¸­æ–­ç»­ä¸‹ï¼Œè¯»å–æ—¶headeræœ‰é—®é¢˜

ç¬¬äºŒæ¬¡å®Œæ•´ä¸‹è½½

!!! Exception during processing!!! With local_files_only set to False, you must first locally save the configuration in the following path: 'openai/clip-vit-large-patch14'.

Photon_v1_fp16ä¸å«clipï¼Œéœ€è¦è°ƒç”¨ Chilloutmix-Ni-pruned-fp16-fix.safetensors çš„ clip

ç”Ÿæˆè´¨é‡è¾ƒå·®

æ’ä»¶ä½œè€…è¿˜åœ¨ä¿®æ”¹ï¼Œæ‰“è¡¥ä¸      









# å…¶ä»–
## controlnetä½œè€…
https://github.com/lllyasviel

å¼ å•æ•ï¼ˆLyuminZhangï¼‰æ˜¯ä¸€ååšå£«ã€‚è‡ª2022å¹´èµ·ï¼Œä»–åœ¨æ–¯å¦ç¦å¤§å­¦Maneesh Agrawalaæ•™æˆçš„æŒ‡å¯¼ä¸‹æ”»è¯»è®¡ç®—æœºç§‘å­¦ä¸“ä¸šã€‚åœ¨æ­¤ä¹‹å‰ï¼Œä»–è‡ª2021å¹´èµ·åœ¨é¦™æ¸¯ä¸­æ–‡å¤§å­¦é»„å¤©è¿›æ•™æˆå®éªŒå®¤æ‹…ä»»ç ”ç©¶åŠ©ç†ã€‚ä»–è¿˜ä¸æ•™æˆåˆä½œåŸƒå¾·åŠ Â·è¥¿è«-å¡æ‹‰ (Edgar Simo-Serra)å‚ä¸äº†è®¸å¤šæœ‰è¶£çš„é¡¹ç›®ã€‚ä»–è·å¾—äº†å·¥ç¨‹å­¦å­¦å£«å­¦ä½ã€‚ 2021å¹´äºè‹å·å¤§å­¦è·å¾—åšå£«å­¦ä½ï¼Œå¯¼å¸ˆä¸ºå­£æ¯…æ•™æˆå’Œ åˆ˜æ˜¥å¹³æ•™æˆã€‚

é—²æš‡æ—¶ï¼Œå•æ•å–œæ¬¢å¼€å‘æ¸¸æˆã€‚ Lvmin æ˜¯ä¸€æ¬¾åä¸º YGOPro2 çš„ Unity å¡ç‰Œæ¸¸æˆçš„ä½œè€…ã€‚å¦‚æœä½ åœ¨Googleæˆ–YouTubeä¸Šæœç´¢è¿™ä¸ªæ¸¸æˆï¼Œä½ ä¼šå‘ç°å®ƒå¾ˆå—æ¬¢è¿ã€‚è¯¥æ¸¸æˆå·²è¢«ç¿»è¯‘æˆå¤šç§è¯­è¨€ï¼Œåœ¨ä¸–ç•Œå„åœ°æ‹¥æœ‰ç²‰ä¸ã€‚

![alt text](assets/IC-Light/image-12.png)


### PaintingLight

Generating Digital Painting Lighting Effects via RGB-space Geometry (SIGGRAPH2020/TOG2020)


ACM Transactions on Graphics (Presented in ACM SIGGRAPH 2020), January 2020

Lvmin Zhang, Edgar Simo-Serra, Yi Ji, and Chunping Liu


æ‰“å…‰æ–¹å‘å¦ä¸€ç§å®ç°     

ic-lightæœ€å¤§çš„ç‰¹è‰²æ˜¯å…‰ç§ï¼Œå…‰æ–¹å‘çš„å¤šæ ·æ€§ï¼Œå……åˆ†ä½“ç°æ‰©æ•£æ¨¡å‹çš„ç‰¹ç‚¹ï¼Œcontrolçš„ç‰¹è‰²      
controlnetä¹Ÿå¯ä»¥ç®€å•å®ç°æ‰“å…‰æ–¹å‘     


æ—¨åœ¨å¯»æ‰¾ä¸€ç§æ“çºµæ•°å­—ç»˜ç”»ä¸­çš„ç…§æ˜çš„æ–¹æ³•ã€‚è¯¥é¡¹ç›®äº2019å¹´1æœˆå·¦å³å¯åŠ¨ï¼Œæ ¸å¿ƒç®—æ³•äº2020å¹´è¢«ACM Transitions on Graphicsæ¥å—ã€‚

ç”±äºæ•°å­—ç»˜ç”»å…‰ç…§æ•°æ®ä¸æ˜“è·å¾—ï¼Œå› æ­¤è¯¥ç®—æ³•æ²¡æœ‰ä½¿ç”¨æ·±åº¦å­¦ä¹ ã€‚æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨é¢œè‰²å‡ ä½•æ¥æ„å»ºä¸€ä¸ªæ„ŸçŸ¥ä¸Šå¯è¡Œçš„é‡æ–°ç…§æ˜ç³»ç»Ÿã€‚è¿™ç§é‡æ–°ç…§æ˜å¯èƒ½åœ¨ç‰©ç†ä¸Šä¸å‡†ç¡®ï¼Œä½†å¯¹äºè‰ºæœ¯ç”¨ä¾‹æ¥è¯´å·²ç»è¶³å¤Ÿå¥½äº†ã€‚     
Because digital painting illumination data is not easy to obtain, this algorithm does not use deep learning. The core idea is to make use of `color geometry to build up a perceptually workable relighting system`. Such relighting may not be physically accurate, but are good enough for artistic use cases.     

![alt text](assets/IC-Light/image-15.png)

Q: It is mentioned that this project does not using 
   deep learning, then why it is still required to install tensorflow?

A: This is because we use SRCNN, a tensorflow neural network, to 
   pre-process input images in order to remove JPEG artifacts. Therefore 
   you still need to install tensorflow with a proper version.






æˆ‘ä»¬æå‡ºäº†ä¸€ç§ä»å•ä¸ªå›¾åƒç”Ÿæˆæ•°å­—ç»˜ç”»ç…§æ˜æ•ˆæœçš„ç®—æ³•ã€‚æˆ‘ä»¬çš„ç®—æ³•åŸºäºä¸€ä¸ªå…³é”®çš„è§‚å¯Ÿï¼šè‰ºæœ¯å®¶ä½¿ç”¨è®¸å¤šé‡å çš„ç¬”ç”»æ¥ç»˜åˆ¶ç…§æ˜æ•ˆæœï¼Œå³å…·æœ‰å¯†é›†ç¬”ç”»å†å²çš„åƒç´ å¾€å¾€ä¼šæ”¶é›†æ›´å¤šçš„ç…§æ˜ç¬”ç”»ã€‚åŸºäºè¿™ä¸€è§‚å¯Ÿï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ç®—æ³•ï¼Œæ—¢å¯ä»¥ä½¿ç”¨é¢œè‰²å‡ ä½•æ¥ä¼°è®¡æ•°å­—ç»˜ç”»ä¸­çš„ç¬”ç”»å¯†åº¦ï¼Œç„¶åé€šè¿‡æ¨¡ä»¿è‰ºæœ¯å®¶ä»ç²—åˆ°ç»†çš„å·¥ä½œæµç¨‹æ¥ç”Ÿæˆæ–°é¢–çš„ç¯å…‰æ•ˆæœã€‚é¦–å…ˆä½¿ç”¨æ³¢å½¢å˜æ¢ç”Ÿæˆç²—ç•¥çš„ç¯å…‰æ•ˆæœï¼Œç„¶åæ ¹æ®åŸå§‹æ’å›¾çš„ç¬”åˆ’å¯†åº¦ä¿®é¥°ä¸ºå¯ç”¨çš„ç¯å…‰æ•ˆæœã€‚
æˆ‘ä»¬çš„ç®—æ³•æ˜¯å†…å®¹æ„ŸçŸ¥çš„ï¼Œç”Ÿæˆçš„ç¯å…‰æ•ˆæœè‡ªç„¶é€‚åº”å›¾åƒç»“æ„ï¼Œå¹¶ä¸”å¯ä»¥ç”¨ä½œäº¤äº’å¼å·¥å…·æ¥ç®€åŒ–å½“å‰ä¸ºæ•°å­—å’Œå“‘å…‰ç»˜ç”»ç”Ÿæˆç¯å…‰æ•ˆæœçš„åŠ³åŠ¨å¯†é›†å‹å·¥ä½œæµç¨‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„ç®—æ³•è¿˜å¯ä»¥ä¸ºç…§ç‰‡æˆ– 3D æ¸²æŸ“å›¾åƒç”Ÿæˆå¯ç”¨çš„ç¯å…‰æ•ˆæœã€‚æˆ‘ä»¬é€šè¿‡æ·±å…¥çš„å®šæ€§å’Œå®šé‡åˆ†æï¼ˆåŒ…æ‹¬æ„ŸçŸ¥ç”¨æˆ·ç ”ç©¶ï¼‰æ¥è¯„ä¼°æˆ‘ä»¬çš„æ–¹æ³•ã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•ä¸ä»…èƒ½å¤Ÿç›¸å¯¹äºç°æœ‰æ–¹æ³•äº§ç”Ÿè‰¯å¥½çš„ç…§æ˜æ•ˆæœï¼Œè€Œä¸”è¿˜èƒ½å¤Ÿæ˜¾ç€å‡å°‘æ‰€éœ€çš„äº¤äº’æ—¶é—´ã€‚








### Stable Diffusion WebUI Forge

Stable Diffusion WebUI Forge æ˜¯ä¸€ä¸ªåŸºäºStable Diffusion WebUIï¼ˆåŸºäºGradioï¼‰çš„å¹³å°ï¼Œå¯ç®€åŒ–å¼€å‘ã€ä¼˜åŒ–èµ„æºç®¡ç†å¹¶åŠ å¿«æ¨ç†é€Ÿåº¦ã€‚

â€œForgeâ€è¿™ä¸ªåå­—çš„çµæ„Ÿæ¥è‡ªäºâ€œMinecraft Forgeâ€ã€‚è¯¥é¡¹ç›®æ—¨åœ¨æˆä¸º SD WebUI çš„ Forgeã€‚

ä¸åŸå§‹ WebUIï¼ˆé’ˆå¯¹ 1024 åƒç´ çš„ SDXL æ¨ç†ï¼‰ç›¸æ¯”ï¼Œæ‚¨å¯ä»¥æœŸå¾…ä»¥ä¸‹åŠ é€Ÿï¼š

å¦‚æœæ‚¨ä½¿ç”¨å¸¸è§çš„ GPUï¼ˆå¦‚ 8GB vramï¼‰ï¼Œæ‚¨å¯ä»¥é¢„æœŸæ¨ç†é€Ÿåº¦ï¼ˆit/sï¼‰ä¼šæé«˜çº¦30~45%ï¼ŒGPU å†…å­˜å³°å€¼ï¼ˆåœ¨ä»»åŠ¡ç®¡ç†å™¨ä¸­ï¼‰å°†ä¸‹é™çº¦ 700MB è‡³ 1.3GBï¼Œæœ€å¤§æ‰©æ•£åˆ†è¾¨ç‡ï¼ˆä¸ä¼š OOMï¼‰å°†å¢åŠ çº¦ 2 å€åˆ° 3 å€ï¼Œæœ€å¤§æ‰©æ•£æ‰¹é‡å¤§å°ï¼ˆä¸ä¼š OOMï¼‰å°†å¢åŠ çº¦ 4 å€åˆ° 6 å€ã€‚

å¦‚æœæ‚¨ä½¿ç”¨åŠŸèƒ½è¾ƒå¼±çš„ GPUï¼ˆä¾‹å¦‚ 6GB vramï¼‰ï¼Œåˆ™é¢„è®¡æ¨ç†é€Ÿåº¦ï¼ˆit/sï¼‰å°†æé«˜çº¦ 60~75%ï¼ŒGPU å†…å­˜å³°å€¼ï¼ˆåœ¨ä»»åŠ¡ç®¡ç†å™¨ä¸­ï¼‰å°†ä¸‹é™çº¦ 800MB è‡³ 1.5GBï¼ˆæœ€å¤§ï¼‰æ‰©æ•£åˆ†è¾¨ç‡ï¼ˆä¸ä¼š OOMï¼‰å°†å¢åŠ çº¦ 3 å€ï¼Œæœ€å¤§æ‰©æ•£æ‰¹é‡å¤§å°ï¼ˆä¸ä¼š OOMï¼‰å°†å¢åŠ çº¦ 4 å€ã€‚

å¦‚æœæ‚¨ä½¿ç”¨åƒ 4090 è¿™æ ·å…·æœ‰ 24GB vram çš„å¼ºå¤§ GPUï¼Œæ‚¨å¯ä»¥é¢„æœŸæ¨ç†é€Ÿåº¦ (it/s) ä¼šæé«˜çº¦3~6%ï¼ŒGPU å†…å­˜å³°å€¼ï¼ˆåœ¨ä»»åŠ¡ç®¡ç†å™¨ä¸­ï¼‰å°†ä¸‹é™çº¦ 1GB è‡³ 1.4GBï¼Œæœ€å¤§æ‰©æ•£åˆ†è¾¨ç‡ï¼ˆä¸ä¼š OOMï¼‰å°†å¢åŠ çº¦ 1.6 å€ï¼Œæœ€å¤§æ‰©æ•£æ‰¹é‡å¤§å°ï¼ˆä¸ä¼š OOMï¼‰å°†å¢åŠ çº¦ 2 å€ã€‚

å¦‚æœä½¿ç”¨ ControlNet for SDXLï¼Œæœ€å¤§ ControlNet æ•°é‡ï¼ˆä¸ä¼š OOMï¼‰å°†å¢åŠ çº¦ 2 å€ï¼Œä½¿ç”¨ SDXL+ControlNet çš„é€Ÿåº¦å°†åŠ å¿«çº¦ 30~45%ã€‚

Forge å¸¦æ¥çš„å¦ä¸€ä¸ªéå¸¸é‡è¦çš„å˜åŒ–æ˜¯Unet Patcherã€‚ä½¿ç”¨ Unet Patcherï¼ŒSelf-Attention Guidanceã€Kohya High Res Fixã€FreeUã€StyleAlignã€Hypertile ç­‰æ–¹æ³•éƒ½å¯ä»¥åœ¨å¤§çº¦ 100 è¡Œä»£ç ä¸­å®ç°ã€‚

å¤šäºäº† Unet Patcherï¼Œè®¸å¤šæ–°çš„ä¸œè¥¿ç°åœ¨éƒ½å¯ä»¥åœ¨ Forge ä¸­å®ç°å¹¶å¾—åˆ°æ”¯æŒï¼ŒåŒ…æ‹¬ SVDã€Z123ã€masked Ip-adapterã€masked controlnetã€photomaker ç­‰ã€‚

æ— éœ€å†å¯¹ UNet è¿›è¡Œ Monkeypatch å¹¶ä¸å…¶ä»–æ‰©å±•å‘ç”Ÿå†²çªï¼

Forge è¿˜æ·»åŠ äº†ä¸€äº›é‡‡æ ·å™¨ï¼ŒåŒ…æ‹¬ä½†ä¸é™äº DDPMã€DDPM Karrasã€DPM++ 2M Turboã€DPM++ 2M SDE Turboã€LCM Karrasã€Euler A Turbo ç­‰ï¼ˆLCM ä» 1.7.0 å¼€å§‹å°±å·²ç»åœ¨åŸå§‹ webui ä¸­ï¼‰ã€‚

æœ€åï¼ŒForge æ‰¿è¯ºæˆ‘ä»¬åªä¼šåšå¥½æˆ‘ä»¬çš„å·¥ä½œã€‚ Forge æ°¸è¿œä¸ä¼šå¯¹ç”¨æˆ·ç•Œé¢æ·»åŠ ä¸å¿…è¦çš„ä¸»è§‚æ›´æ”¹ã€‚æ‚¨ä»åœ¨ä½¿ç”¨ 100% è‡ªåŠ¨ 1111 WebUIã€‚




### Style2Paints
sketch + style = paints ğŸ¨ (TOG2018/SIGGRAPH2018ASIA)

![alt text](assets/IC-Light/image-8.png)

éæ‰©æ•£æ¨¡å‹    


    2022.08.15 - Lvmin's article is accepted to SIGGRAPH ASIA 2022, journal track.
    2022.06.15 - See some recent announcements of Style2Paints (Project SEPA) here.
    2022.01.09 - See some recent announcements of Style2Paints (Project SEPA) here.
    2021.06.09 - An article on shadow drawing is accepted to ICCV 2021 as Oral.
    2021.06.01 - The Project SEPA is decided to be released before 2022.
    2021.03.22 - The next version of Style2Paints will be called Project SEPA. See also the twitter post.





Help human in their standard coloring workflow!
Most human artists are familiar with this workflow:

sketching -> color filling/flattening -> gradients/details adding -> shading
And the corresponding layers are:

lineart layers + flat color layers + gradient layers + shading layers
Style2paints V4 is designed for this standard coloring workflow! In style2paints V4, you can automatically get separated results from each step!

![alt text](assets/IC-Light/image-9.png)

![alt text](assets/IC-Light/image-10.png)

![alt text](assets/IC-Light/image-11.png)


![alt text](assets/IC-Light/image-13.png)

![alt text](assets/IC-Light/image-14.png)



### fooocus


https://github.com/lllyasviel/Fooocus


About    
Focus on prompting and generating

![alt text](assets/IC-Light/image-1.png)

Fooocus is an image generating software (based on Gradio).

Fooocus is a rethinking of Stable Diffusion and Midjourneyâ€™s designs:

Learned from Stable Diffusion, the software is offline, open source, and free.

Learned from Midjourney, the manual tweaking is not needed, and users only need to focus on the prompts and images.












## Swarm UI
alternate comfyui

https://github.com/Stability-AI/StableSwarmUI


StableSwarmUI, A Modular Stable Diffusion Web-User-Interface, with an emphasis on making powertools easily accessible, high performance, and extensibility.

![alt text](assets/IC-Light/image.png)


## æ—©æœŸç ”ç©¶ä¹Ÿèƒ½æ§åˆ¶æ‰“å…‰ã€‚è€Œä¸”æ•°æ®é›†å®Œå–„


### Acquiring the Reflectance Field of a Human Face
https://www.pauldebevec.com/Research/LS/

https://www.pauldebevec.com/Research/LS/debevec-siggraph2000-high.pdf

è·å–äººè„¸åå°„åœº    
Paul Debevecã€Tim Hawkinsã€Chris Tchouã€Haarm-Pieter Duikerã€Westley Sarokin å’ŒMark Sagar      
SIGGRAPH 2000 ä¼šè®®è®ºæ–‡é›†

2004 å¹´ 4 æœˆ 10 æ—¥



æ‘˜è¦ï¼š

æˆ‘ä»¬æå‡ºäº†ä¸€ç§è·å–äººè„¸åå°„åœºçš„æ–¹æ³•ï¼Œå¹¶ä½¿ç”¨è¿™äº›æµ‹é‡ç»“æœåœ¨å…‰ç…§å’Œè§†ç‚¹çš„ä»»æ„å˜åŒ–ä¸‹æ¸²æŸ“äººè„¸ã€‚æˆ‘ä»¬é¦–å…ˆä½¿ç”¨å…‰å°åœ¨å…¥å°„ç…§æ˜æ–¹å‘çš„å¯†é›†é‡‡æ ·ä¸‹ä»ä¸€å°ç»„è§†ç‚¹è·å–é¢éƒ¨å›¾åƒã€‚ç„¶åï¼Œæˆ‘ä»¬æ ¹æ®ç…§æ˜æ–¹å‘ç©ºé—´ä¸Šçš„æ¯ä¸ªè§‚å¯Ÿåˆ°çš„å›¾åƒåƒç´ çš„å€¼æ„å»ºåå°„å‡½æ•°å›¾åƒã€‚æ ¹æ®åå°„ç‡å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥ä»¥ä»»ä½•å½¢å¼çš„é‡‡æ ·æˆ–è®¡ç®—ç…§æ˜ä»åŸå§‹è§†ç‚¹ç›´æ¥ç”Ÿæˆé¢éƒ¨å›¾åƒã€‚ä¸ºäº†æ”¹å˜è§†ç‚¹ï¼Œæˆ‘ä»¬ä½¿ç”¨çš®è‚¤åå°„ç‡æ¨¡å‹æ¥ä¼°è®¡æ–°è§†ç‚¹çš„åå°„ç‡å‡½æ•°çš„å¤–è§‚ã€‚æˆ‘ä»¬é€šè¿‡åœ¨æ–°é¢–çš„ç…§æ˜å’Œè§†ç‚¹ä¸‹åˆæˆäººè„¸çš„æ¸²æŸ“æ¥æ¼”ç¤ºè¯¥æŠ€æœ¯ã€‚

![alt text](assets/IC-Light/image-6.png)




### GeoWizard
GeoWizard: Unleashing the Diffusion Priors for 3D Geometry Estimation from a Single Image    

[Submitted on 18 Mar 2024]     
GeoWizard: Unleashing the Diffusion Priors for 3D Geometry Estimation from a Single Image     

https://github.com/fuxiao0719/GeoWizard

æˆ‘ä»¬å¼•å…¥äº† GeoWizardï¼Œä¸€ç§æ–°çš„ç”ŸæˆåŸºç¡€æ¨¡å‹ï¼Œæ—¨åœ¨ä»å•ä¸ªå›¾åƒä¼°è®¡å‡ ä½•å±æ€§ï¼Œä¾‹å¦‚æ·±åº¦å’Œæ³•çº¿ã€‚å°½ç®¡è¯¥é¢†åŸŸå·²ç»è¿›è¡Œäº†å¤§é‡ç ”ç©¶ï¼Œä½†ç”±äºå…¬å¼€æ•°æ®é›†çš„å¤šæ ·æ€§ä½å’Œè´¨é‡å·®ï¼Œè¿›å±•å—åˆ°å¾ˆå¤§é™åˆ¶ã€‚å› æ­¤ï¼Œå…ˆå‰çš„å·¥ä½œè¦ä¹ˆå—é™äºæœ‰é™çš„åœºæ™¯ï¼Œè¦ä¹ˆæ— æ³•æ•æ‰å‡ ä½•ç»†èŠ‚ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è¯æ˜ç”Ÿæˆæ¨¡å‹ä¸ä¼ ç»Ÿåˆ¤åˆ«æ¨¡å‹ï¼ˆä¾‹å¦‚ CNN å’Œ Transformerï¼‰ç›¸åï¼Œå¯ä»¥æœ‰æ•ˆè§£å†³å›ºæœ‰çš„ä¸é€‚å®šé—®é¢˜ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è¡¨æ˜ï¼Œåˆ©ç”¨æ‰©æ•£å…ˆéªŒå¯ä»¥æ˜¾ç€æé«˜æ³›åŒ–èƒ½åŠ›ã€ç»†èŠ‚ä¿ç•™å’Œèµ„æºä½¿ç”¨æ•ˆç‡ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æ‰©å±•äº†åŸå§‹çš„ç¨³å®šæ‰©æ•£æ¨¡å‹æ¥è”åˆé¢„æµ‹æ·±åº¦å’Œæ³•çº¿ï¼Œä»è€Œå…è®¸ä¸¤ç§è¡¨ç¤ºä¹‹é—´çš„ç›¸äº’ä¿¡æ¯äº¤æ¢å’Œé«˜åº¦ä¸€è‡´æ€§ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„ç­–ç•¥ï¼Œå°†å„ç§åœºæ™¯çš„å¤æ‚æ•°æ®åˆ†å¸ƒåˆ†ç¦»æˆä¸åŒçš„å­åˆ†å¸ƒã€‚è¿™ç§ç­–ç•¥ä½¿æˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿè¯†åˆ«ä¸åŒçš„åœºæ™¯å¸ƒå±€ï¼Œä»¥å“è¶Šçš„ä¿çœŸåº¦æ•è· 3D å‡ ä½•å›¾å½¢ã€‚ GeoWizard ä¸ºé›¶é•œå¤´æ·±åº¦å’Œæ³•çº¿é¢„æµ‹è®¾å®šäº†æ–°çš„åŸºå‡†ï¼Œæ˜¾ç€å¢å¼ºäº†è®¸å¤šä¸‹æ¸¸åº”ç”¨ï¼Œä¾‹å¦‚ 3D é‡å»ºã€2D å†…å®¹åˆ›å»ºå’Œæ–°é¢–çš„è§†ç‚¹åˆæˆã€‚     



åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼ŒGeoWizard å°†å›¾åƒã€GT æ·±åº¦å’Œ GT æ³•çº¿é€šè¿‡å†»ç»“çš„ VAE ç¼–ç åˆ°æ½œåœ¨ç©ºé—´ä¸­ï¼Œå¹¶å½¢æˆä¸¤ä¸ªä¸²è”çš„å‡ ä½•ç»„ã€‚æ¯ä¸ªç»„éƒ½è¢«è¾“å…¥ U-Netï¼Œåœ¨å‡ ä½•åˆ‡æ¢å™¨çš„æŒ‡å¯¼ä¸‹ç”Ÿæˆæ·±åº¦æˆ–æ­£å¸¸åŸŸçš„è¾“å‡ºã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†åœºæ™¯æç¤ºï¼Œä»¥ä½¿ç”¨ä¸‰ç§å¯èƒ½çš„åœºæ™¯å¸ƒå±€ï¼ˆå®¤å†…/å®¤å¤–/ç‰©ä½“ï¼‰ä¹‹ä¸€ç”Ÿæˆç»“æœã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œç»™å®šå›¾åƒã€åœºæ™¯æç¤ºã€åˆå§‹æ·±åº¦å™ªå£°å’Œæ³•çº¿å™ªå£°ï¼ŒGeoWizard å¯ä»¥è”åˆç”Ÿæˆé«˜è´¨é‡çš„æ·±åº¦å’Œæ³•çº¿ã€‚

![alt text](assets/IC-Light/image-7.png)





### switchlight
https://arxiv.org/pdf/2402.18848




### Total Relighting:
Learning to Relight Portraits for Background Replacement   
https://augmentedperception.github.io/total_relighting/   
SIGGRAPH 2021 æŠ€æœ¯è§†é¢‘

![alt text](assets/IC-Light/image-5.png)    
è€æ–¹æ³•æ•ˆæœå·²ç»å¾ˆå¥½     
åŒ…æ‹¬ç°åœ¨è…¾è®¯ä¼šè®®çš„æ¢èƒŒæ™¯ï¼Œå°±æ˜¯æœ‰æ—¶å€™æœ‰ç‚¹æŠ–ã€‚ic-lightä¸»æ‰“çš„æ‰“å…‰ç”šè‡³éƒ½ä¸èƒ½ç®—æ–°é¢–æŠ€æœ¯    
å¯èƒ½æ˜¯å¯¹äºlimitçš„ä¼˜åŒ–å§      


æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºäººåƒé‡æ–°ç…§æ˜å’ŒèƒŒæ™¯æ›¿æ¢çš„æ–°é¢–ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿå¯ä¿æŒé«˜é¢‘è¾¹ç•Œç»†èŠ‚å¹¶å‡†ç¡®åˆæˆæ–°é¢–ç…§æ˜ä¸‹çš„ä¸»ä½“å¤–è§‚ï¼Œä»è€Œä¸ºä»»ä½•æ‰€éœ€åœºæ™¯ç”Ÿæˆé€¼çœŸçš„åˆæˆå›¾åƒã€‚æˆ‘ä»¬çš„æŠ€æœ¯åŒ…æ‹¬é€šè¿‡ Alpha æŠ å›¾ã€é‡æ–°ç…§æ˜å’Œåˆæˆè¿›è¡Œå‰æ™¯ä¼°è®¡ã€‚æˆ‘ä»¬è¯æ˜ï¼Œè¿™äº›é˜¶æ®µä¸­çš„æ¯ä¸€ä¸ªéƒ½å¯ä»¥åœ¨é¡ºåºç®¡é“ä¸­å¤„ç†ï¼Œæ— éœ€ä½¿ç”¨å…ˆéªŒï¼ˆä¾‹å¦‚å·²çŸ¥èƒŒæ™¯æˆ–å·²çŸ¥ç…§æ˜ï¼‰ï¼Œä¹Ÿæ— éœ€ä¸“é—¨çš„é‡‡é›†æŠ€æœ¯ï¼Œä»…ä½¿ç”¨å•ä¸ª RGB è‚–åƒå›¾åƒå’Œæ–°é¢–çš„ç›®æ ‡ HDR ç…§æ˜ç¯å¢ƒä½œä¸ºè¾“å…¥ã€‚æˆ‘ä»¬ä½¿ç”¨åœ¨å…‰çº§è®¡ç®—ç…§æ˜ç³»ç»Ÿä¸­æ•è·çš„å¯¹è±¡çš„é‡ç…§è‚–åƒæ¥è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ï¼Œè¯¥ç³»ç»Ÿè®°å½•äº†å¤šç§ç…§æ˜æ¡ä»¶ã€é«˜è´¨é‡çš„å‡ ä½•å½¢çŠ¶å’Œå‡†ç¡®çš„ alpha é®ç½©ã€‚ä¸ºäº†æ‰§è¡Œé€¼çœŸçš„é‡æ–°ç…§æ˜ä»¥è¿›è¡Œåˆæˆï¼Œæˆ‘ä»¬åœ¨æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„æ¯åƒç´ ç…§æ˜è¡¨ç¤ºï¼Œå®ƒæ˜ç¡®åœ°æ¨¡æ‹Ÿäº†å¤–è§‚çš„æ¼«åå°„å’Œé•œé¢åå°„åˆ†é‡ï¼Œç”Ÿæˆå…·æœ‰ä»¤äººä¿¡æœçš„æ¸²æŸ“éæœ—ä¼¯æ•ˆæœï¼ˆå¦‚é•œé¢é«˜å…‰ï¼‰çš„é‡æ–°ç…§æ˜è‚–åƒã€‚å¤šæ¬¡å®éªŒå’Œæ¯”è¾ƒè¡¨æ˜äº†æ‰€æå‡ºçš„æ–¹æ³•åº”ç”¨äºé‡å¤–å›¾åƒæ—¶çš„æœ‰æ•ˆæ€§ã€‚




### Relightful Harmonization
[Submitted on 11 Dec 2023 (v1), last revised 7 Apr 2024 (this version, v2)]      
Relightful Harmonization: Lighting-aware Portrait Background Replacement

è‚–åƒåè°ƒæ—¨åœ¨å°†æ‹æ‘„å¯¹è±¡åˆæˆåˆ°æ–°çš„èƒŒæ™¯ä¸­ï¼Œè°ƒæ•´å…¶ç¯å…‰å’Œé¢œè‰²ä»¥ç¡®ä¿ä¸èƒŒæ™¯åœºæ™¯çš„å’Œè°ã€‚ç°æœ‰çš„åè°ƒæŠ€æœ¯é€šå¸¸åªä¸“æ³¨äºè°ƒæ•´å‰æ™¯çš„å…¨å±€é¢œè‰²å’Œäº®åº¦ï¼Œè€Œå¿½ç•¥äº†èƒŒæ™¯ä¸­çš„å…³é”®ç…§æ˜çº¿ç´¢ï¼Œä¾‹å¦‚æ˜æ˜¾çš„ç…§æ˜æ–¹å‘ï¼Œä»è€Œå¯¼è‡´ä¸åˆ‡å®é™…çš„æ„å›¾ã€‚æˆ‘ä»¬æ¨å‡º Relightful Harmonizationï¼Œè¿™æ˜¯ä¸€ç§ç…§æ˜æ„ŸçŸ¥æ‰©æ•£æ¨¡å‹ï¼Œæ—¨åœ¨ä½¿ç”¨ä»»ä½•èƒŒæ™¯å›¾åƒæ— ç¼åè°ƒå‰æ™¯è‚–åƒçš„å¤æ‚ç…§æ˜æ•ˆæœã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ†ä¸‰ä¸ªé˜¶æ®µå±•å¼€ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¼•å…¥ä¸€ä¸ªç…§æ˜è¡¨ç¤ºæ¨¡å—ï¼Œè¯¥æ¨¡å—å…è®¸æˆ‘ä»¬çš„æ‰©æ•£æ¨¡å‹å¯¹æ¥è‡ªç›®æ ‡å›¾åƒèƒŒæ™¯çš„ç…§æ˜ä¿¡æ¯è¿›è¡Œç¼–ç ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå¯¹é½ç½‘ç»œï¼Œå®ƒå°†ä»å›¾åƒèƒŒæ™¯ä¸­å­¦ä¹ åˆ°çš„ç…§æ˜ç‰¹å¾ä¸ä»å…¨æ™¯ç¯å¢ƒåœ°å›¾ä¸­å­¦ä¹ åˆ°çš„ç…§æ˜ç‰¹å¾å¯¹é½ï¼Œè¿™æ˜¯åœºæ™¯ç…§æ˜çš„å®Œæ•´è¡¨ç¤ºã€‚æœ€åï¼Œä¸ºäº†è¿›ä¸€æ­¥æé«˜æ‰€æå‡ºæ–¹æ³•çš„çœŸå®æ„Ÿï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„æ•°æ®æ¨¡æ‹Ÿç®¡é“ï¼Œè¯¥ç®¡é“å¯ä»¥ä»å„ç§è‡ªç„¶å›¾åƒä¸­ç”Ÿæˆåˆæˆè®­ç»ƒå¯¹ï¼Œç”¨äºç»†åŒ–æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨è§†è§‰ä¿çœŸåº¦å’Œç…§æ˜è¿è´¯æ€§æ–¹é¢ä¼˜äºç°æœ‰åŸºå‡†ï¼Œåœ¨ç°å®æµ‹è¯•åœºæ™¯ä¸­è¡¨ç°å‡ºå“è¶Šçš„æ³›åŒ–èƒ½åŠ›ï¼Œçªå‡ºäº†å…¶å¤šåŠŸèƒ½æ€§å’Œå®ç”¨æ€§ã€‚




## Photon (sd1.5åº•æ¨¡)
Photon aims to generate photorealistic and visually appealing images effortlessly.

Recommendation for generating the first image with Photon:

Prompt: A simple sentence in natural language describing the image.

Negative: "cartoon, painting, illustration, (worst quality, low quality, normal quality:2)"

Sampler: DPM++ 2M Karras | Steps: 20 | CFG Scale: 6

Size: 512x768 or 768x512

Hires.fix: R-ESRGAN 4x+ | Steps: 10 | Denoising: 0.45 | Upscale x 2

(avoid using negative embeddings unless absolutely necessary)


### development
The development process was somewhat chaotic but essentially:

It started from an old mix.

LORAs were trained on various topics using AI-generated photorealistic images.

These LORAs were mixed within the model using different weights.

In the midst of this mixing, hand generation broke.

LORAs were generated and remixed in an attempt to fix hand generation (not entirely successful).

### limit
In future versions, I will try to:

Completely eliminate the need for a negative prompt to generate high-quality images.

Fix the hand generation issue to minimize instances of poorly drawn hands.

Explore more automated training processes. I would love to have 5,000 or 50,000 high-quality AI-generated photorealistic images for training purposes.




## maskè·å–
comfyui sam mask     



## å‰æ™¯æå–å·¥å…· briaai/RMBG-1.4 

BRIA Background Removal v1.4 


![alt text](assets/IC-Light/image-16.png)

MBG v1.4 æ˜¯æˆ‘ä»¬æœ€å…ˆè¿›çš„èƒŒæ™¯å»é™¤æ¨¡å‹ï¼Œæ—¨åœ¨æœ‰æ•ˆåœ°å°†å„ç§ç±»åˆ«å’Œå›¾åƒç±»å‹çš„å‰æ™¯ä¸èƒŒæ™¯åˆ†å¼€ã€‚è¯¥æ¨¡å‹å·²ç»åœ¨ç²¾å¿ƒæŒ‘é€‰çš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†è®­ç»ƒï¼Œå…¶ä¸­åŒ…æ‹¬ï¼šä¸€èˆ¬åº“å­˜å›¾åƒã€ç”µå­å•†åŠ¡ã€æ¸¸æˆå’Œå¹¿å‘Šå†…å®¹ï¼Œä½¿å…¶é€‚åˆæ”¯æŒå¤§è§„æ¨¡ä¼ä¸šå†…å®¹åˆ›å»ºçš„å•†ä¸šç”¨ä¾‹ã€‚å…¶å‡†ç¡®æ€§ã€æ•ˆç‡å’Œå¤šåŠŸèƒ½æ€§å¯ä¸ç›®å‰é¢†å…ˆçš„å¯ç”¨æºæ¨¡å‹ç›¸åª²ç¾ã€‚å½“å†…å®¹å®‰å…¨ã€åˆæ³•è®¸å¯çš„æ•°æ®é›†å’Œåè§ç¼“è§£è‡³å…³é‡è¦æ—¶ï¼Œå®ƒæ˜¯ç†æƒ³çš„é€‰æ‹©ã€‚


Bria-RMBG æ¨¡å‹ä½¿ç”¨è¶…è¿‡ 12,000 å¼ é«˜è´¨é‡ã€é«˜åˆ†è¾¨ç‡ã€æ‰‹åŠ¨æ ‡è®°ï¼ˆåƒç´ ç²¾åº¦ï¼‰ã€å®Œå…¨è®¸å¯çš„å›¾åƒè¿›è¡Œè®­ç»ƒã€‚æˆ‘ä»¬çš„åŸºå‡†åŒ…æ‹¬å¹³è¡¡çš„æ€§åˆ«ã€å¹³è¡¡çš„ç§æ—å’Œä¸åŒç±»å‹çš„æ®‹ç–¾äººã€‚

å›¾ç‰‡åˆ†å¸ƒï¼š

ç±»åˆ«	åˆ†é…
ä»…å¯¹è±¡	45.11%
æœ‰ç‰©ä½“/åŠ¨ç‰©çš„äºº	25.24%
ä»…é™äºº	17.35%
å¸¦æœ‰æ–‡å­—çš„äºº/ç‰©ä½“/åŠ¨ç‰©	8.52%
çº¯æ–‡æœ¬	2.52%
ä»…é™åŠ¨ç‰©	1.89%

ç±»åˆ«	åˆ†é…
é€¼çœŸ	87.70%
éçœŸå®æ„Ÿ	12.30%

ç±»åˆ«	åˆ†é…
éçº¯è‰²èƒŒæ™¯	52.05%
çº¯è‰²èƒŒæ™¯	47.95%

ç±»åˆ«	åˆ†é…
å•ä¸ªä¸»è¦å‰æ™¯å¯¹è±¡	51.42%
å‰æ™¯ä¸­æœ‰å¤šä¸ªå¯¹è±¡	48.58%

Architecture

RMBG v1.4 is developed on the IS-Net enhanced with our unique training scheme and proprietary dataset. These modifications significantly improve the modelâ€™s accuracy and effectiveness in diverse image-processing scenarios.

RMBG v1.4 æ˜¯åœ¨IS-Netä¸Šå¼€å‘çš„ï¼Œå¹¶é€šè¿‡æˆ‘ä»¬ç‹¬ç‰¹çš„è®­ç»ƒæ–¹æ¡ˆå’Œä¸“æœ‰æ•°æ®é›†è¿›è¡Œäº†å¢å¼ºã€‚è¿™äº›ä¿®æ”¹æ˜¾ç€æé«˜äº†æ¨¡å‹åœ¨ä¸åŒå›¾åƒå¤„ç†åœºæ™¯ä¸­çš„å‡†ç¡®æ€§å’Œæœ‰æ•ˆæ€§ã€‚

### Dichotomous Image Segmentation (DIS)
https://github.com/xuebinqin/DIS

è¿™æ˜¯æˆ‘ä»¬æ–°é¡¹ç›®é«˜ç²¾åº¦äºŒåˆ†å›¾åƒåˆ†å‰²çš„å­˜å‚¨åº“

é«˜ç²¾åº¦äºŒåˆ†å›¾åƒåˆ†å‰²ï¼ˆECCV 2022ï¼‰    
ç§¦å­¦æ–Œã€æˆ´èˆªã€èƒ¡æ™“æ–Œã€èŒƒé‚“å¹³*ã€é‚µå‡Œã€Luc Van Goolã€‚

![alt text](assets/IC-Light/image-17.png)

![alt text](assets/IC-Light/image-18.png)


![alt text](assets/IC-Light/image-19.png)


![alt text](assets/IC-Light/image-20.png)

æˆ‘ä»¬ä¹‹å‰çš„ä½œå“ï¼šU 2 -Netï¼ŒBASNetã€‚












# ç»“å°¾