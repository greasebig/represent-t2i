# 命令

## find
find /home/WujieAITeam/private -type d -name "stable-diffusion-xl-base-1.0"

find /home/WujieAITeam/private -name "mjhq30k_imgs.zip"


## scp传文件
scp -r -P 32483 root@61.170.32.3:/models/playground-v2.5-1024px-aesthetic ./     
注意端口要大写P   
异于ssh   

而且-P 32483 只能放在前面，中间结尾都不行， 即使服务器放在后面，被传输
   




## 终端上网
export http_proxy=127.0.0.1:7890
export https_proxy=127.0.0.1:7890

export http_proxy="http://127.0.0.1:7890"
export https_proxy="http://127.0.0.1:7890"

unset http_proxy
unset https_proxy







## kill 显存
通过以下命令查看僵尸进程    
sudo fuser -v /dev/nvidia*  
找到COMMAND=python的，然后通过以下命令逐一kill僵尸进程    
sudo kill -9 进程q

进程查看 ps -ef




## tmux
tmux kill-session -t edm2  
tmux attach -t edm2   
tmux new-session -s edm2   


## 镜像hug下载

export HF_ENDPOINT=https://hf-mirror.com

huggingface-cli download --repo-type dataset --resume-download playgroundai/MJHQ-30K --local-dir playgroundai/MJHQ-30K

huggingface-cli download --resume-download gpt2 --local-dir gpt2


### 单文件
wget https://hf-mirror.com/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors?download=true

这样一般下载得，需要重命名 'yoso_lora.safetensors?download=true'

而不是  
wget https://hf-mirror.com/runwayml/stable-diffusion-v1-5/blob/main/v1-5-pruned-emaonly.safetensors




## 删除设置的环境变量

unset HF_ENDPOINT   
echo $HF_ENDPOINT    






## Linux统计文件夹下的文件数目
统计当前目录下文件的个数（不包括目录）  
ls -l | grep "^-" | wc -l   
统计当前目录下文件的个数（包括子目录）   
ls -lR| grep "^-" | wc -l   
查看某目录下文件夹(目录)的个数（包括子目录）  
ls -lR | grep "^d" | wc -l   

ls -l   
长列表输出该目录下文件信息(注意这里的文件是指目录、链接、设备文件等)，每一行对应一个文件或目录，ls -lR是列出所有文件，包括子目录。

grep "^-"   
过滤ls的输出信息，只保留一般文件，只保留目录是grep "^d"。

wc -l   
统计输出信息的行数，统计结果就是输出信息的行数，一行信息对应一个文件，所以就是文件的个数。





## 端口转发
此外，如果我们开发的是 WEB 应用，为了能够浏览到远程主机上的应用，我们可以利用另一个端口转发的功能来实现。


## 远程服务器vscode debug
必须先在服务器上装python和python debugger扩展   
没有就是vscode版本太久，某些方面不兼容了    



## diffusers转ckpt safetensors
python scripts/convert_diffusers_to_original_stable_diffusion.py --model_path model_dir --checkpoint_path path_to_ckpt.ckpt




## github镜像
github在国内会碰到下载不稳定的情况，推荐使用镜像

https://bgithub.xyz/
将前缀更换即可，例如：

https://github.com/OpenGVLab/CaFo
https://bgithub.xyz/OpenGVLab/CaFo



## conda本机复制环境 删除

conda create --name <new_environment_name> --clone <existing_environment_name>

conda remove --name <environment_name> --all

## conda跨机环境
同一区硬盘    
conda install -c conda-forge conda-pack    

conda pack -n <envsname> -o conda_envsname.tar.gz

mkdir -p /root/anaconda3/envs/<envsname>    

tar -xzf /root/tempfile/conda_envsname.tar.gz -C /root/miniconda3/envs/<envsname>  


tar -xzf /root/tempfile/conda_envsname.tar.gz -C /root/anaconda3/envs/<envsname>    

常见错误：   
conda装torch，又使用pip装新版本    

    CondaPackError: 
    Files managed by conda were found to have been deleted/overwritten in the
    following packages:

    - pytorch 1.13.1:
        lib/python3.10/site-packages/torch-1.13.1-py3.10.egg-info/PKG-INFO
        lib/python3.10/site-packages/torch-1.13.1-py3.10.egg-info/SOURCES.txt
        lib/python3.10/site-packages/torch-1.13.1-py3.10.egg-info/dependency_links.txt
        + 3 others
    - torchvision 0.14.1:
        lib/python3.10/site-packages/torchvision-0.14.1-py3.10.egg-info/PKG-INFO
        lib/python3.10/site-packages/torchvision-0.14.1-py3.10.egg-info/SOURCES.txt
        lib/python3.10/site-packages/torchvision-0.14.1-py3.10.egg-info/dependency_links.txt
        + 4 others

    This is usually due to `pip` uninstalling or clobbering conda managed files,
    resulting in an inconsistent environment. Please check your environment for
    conda/pip conflicts using `conda list`, and fix the environment by ensuring
    only one version of each package is installed (conda preferred).




## 服务器网页映射本地
端口转发？    

ssh -L [本地端口]:[远程地址]:[远程端口] [用户]@[服务器地址   
例如：ssh -L 8080:127.0.0.1:80  user@example.co    

不设置本地地址就默认是 127.0.0.1    
或者 http://localhost:8080   


ssh -L 8080:0.0.0.0:11223 root@hz-t3.matpool.com    
ssh -L 8080:0.0.0.0:11223 root@hz-t3.matpool.com -p 29705   
直接就登录了     
macbook还是比较不一样的，既能登录又能映射     



## huggingface登录下载
huggingface-cli login   

https://huggingface.co/settings/tokens


## 装git lfs
curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash    
sudo apt-get install git-lfs     




## 终端查找历史命令

使用 Ctrl + R 进行反向搜索：
您可以按下 Ctrl + R 键，然后开始输入部分命令。终端会自动显示最接近的匹配项。继续按 Ctrl + R 将继续在历史记录中搜索更早的命令。


## torch将变量从cpu转到cuda，相同浮点数
noise = noise.to('cuda')

mat1 and mat2 must have the same dtype
tensor = torch.randn(3, 3)
tensor_float16 = tensor.to(torch.float16)



## vim退出保存
:wq   
:q   
:q!   


vim删除所有   
esc.不要进入：     
使用 ggdG 命令。这个命令的含义是：   
gg 将光标移动到文件的开头。   
dG 删除从当前光标位置到文件末尾的所有内容。   



## pip中科大源
pip install torch -i https://pypi.mirrors.ustc.edu.cn/simple/    

https://mirrors.cloud.tencent.com





这些源都不如外网几十mb快   

## 查看机器型号下载cuda
uname -m   
arch   
lsb_release -a   

## 软连接
ln -s 源文件 目标文件

hug上下载的权重有软连接，直接mv很多移动不了   



## 手装xformers
用它的自动脚本又慢又久     
简直愚蠢    

torch2.1.2+cu118      
pip install xformers==0.0.22.post4 --index-url https://download.pytorch.org/whl/cu118    
Collecting torch==2.1.0 (from xformers==0.0.22.post4)    

3090 2号    
xformers                          0.0.20     
torch                             2.0.1+cu118    
`正常使用`   


3090 1号原镜像    
torch                             1.13.1+cu117   
xformers                          0.0.16rc425    

3090 1号    
torch2.1.2+cu118  py311   
pip install xformers==0.0.23.post1 --index-url https://download.pytorch.org/whl/cu118       
没有冲突   
`正常使用`   



# 结尾




