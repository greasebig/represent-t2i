# 为什么forge比webui快那么多 显存还小
整体较快    
插件层面 cn multi较快

Forge backend removes all WebUI's codes related to resource management and reworked everything. All previous CMD flags like medvram, lowvram, medvram-sdxl, precision full, no half, no half vae, attention_xxx, upcast unet, ... are all REMOVED. Adding these flags will not cause error but they will not do anything now. We highly encourage Forge users to remove all cmd flags and let Forge to decide how to load models.


Forge 后端删除了所有与资源管理相关的 WebUI 代码并重新设计了所有内容。


Without any cmd flag, Forge can run SDXL with 4GB vram and SD1.5 with 2GB vram.



UNet Patcher   
Note that Forge does not use any other software as backend. The full name of the backend is Stable Diffusion WebUI with Forge backend, or for simplicity, the Forge backend. The API and python symbols are made similar to previous software only for reducing the learning cost of developers.


Now developing an extension is super simple. We finally have a patchable UNet.

Below is using one single file with 80 lines of codes to support FreeU:

in my tests, forge was only faster on low end hardware when compared to sdnext with lowvram as it's more efficient with aggressive model offloading. but slower in pretty much all other scenarios.

为什么offload还能比别人快？？

文生图更快

我觉得 Forge 更高效的地方在于 RAM 使用和模型切换。

您是否因为 Forge 的智能卸载等而避免了高分辨率下的 OOM 错误？您的特定显卡的加速效果是否显著？您是否使用 Forge 独有（而非自动）工具，如 Layer Diffuse 或 IP Adapter masking？如果是，那么它可能值得。

由于有“永不 OOM”选项卡，我能够通过 hires.fix 生成高分辨率图像，而无需额外的脚本。


3080 10GB

（WEBUI 时间/手动计时器）

A1111 - 5 张图片 - 832x1216 - SDXL turbo - 11 个步骤 - DPM++SDE KARRAS - 57.5 / 60.12

Forge - 5 张图片 - 832x1216 - SDXL turbo - 11 个步骤 -DPM++SDE KARRAS - 50.1 / 51.39

他是controlnet模块的发明者。

它只是具有更高效后端的自动化系统。 

对我来说，它在低端 GPU 上的速度是原来的两倍，所以它实际上是一个游戏规则的改变者








# 结尾