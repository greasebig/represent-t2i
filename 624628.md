# hidiffusion
å…³æ³¨comfyuiæ’ä»¶åŸç”Ÿå®ç°

sd.nextå·²ç»æ”¯æŒ    
4.29   
ä¼°è®¡æ˜¯ç›´æ¥ä½¿ç”¨diffusers    




ä¼˜å…ˆçº§åº”è¯¥æ˜¯hidiffusion ç„¶åcfg++     
æˆ–è€…cfgè®¾æ³•hookè¿‡å» å·²æœ‰ä¸€äº›ä»£ç      
ä½†æˆ‘æ„Ÿè§‰æ•ˆæœæ²¡é‚£ä¹ˆå¥½       

æ–‡ç”Ÿå›¾åŠŸèƒ½ sdxlä¼˜å…ˆæ”¯æŒ

Update

2024.6.19 - ğŸ’¥ Integrated into OpenBayes, see the demo. Thank OpenBayes team!

2024.6.16 - ğŸ’¥ Support PyTorch 2.X.

2024.6.16 - ğŸ’¥ Fix non-square generation issue. Now HiDiffusion supports more image sizes and aspect ratios.

2024.5.7 - ğŸ’¥ Support image-to-image task, see here.

2024.4.16 - ğŸ’¥ Release source code.


å¦‚ä½•åœ¨ Automatic1111 Stable Diffusion Web UI ä¸­ä½¿ç”¨å®ƒï¼ˆé€‚ç”¨äº SD 1.5ã€XL ç­‰ï¼‰ #8    
è¿™ä¸ªè®¨è®ºå¤ªæ—© 5.11æœ€æ™š      

ComfyUI æ”¯æŒå—ï¼Ÿ #1     
è¿™ä¸ªä¹Ÿå¾ˆæ—© 5.22æœ€æ™š

https://github.com/blepping/comfyui_jankhidiffusion#use-with-controlnet     
è¿™ä¸ªåŸç”Ÿæ’ä»¶æ›´æ–°äº 5.21æœ€æ™š éš¾ä»¥é€‚ç”¨     


https://github.com/florestefano1975/ComfyUI-HiDiffusion    
è¿™ä¸ªdiffusersåŒ…è£…æ’ä»¶zuiwangengä¿¡èª‰5.4 ä¹Ÿå¤ªæ—©




Supported Tasks
âœ… Text-to-image
âœ… ControlNet, including text-to-image, image-to-image
âœ… Inpainting

Supported Models
âœ… Stable Diffusion XL
âœ… Stable Diffusion XL Turbo
âœ… Stable Diffusion v2
âœ… Stable Diffusion v1
Note: HiDiffusion also supports the downstream diffusion models based on these repositories, such as Ghibli-Diffusion, Playground, etc.

é«˜åˆ†è¾¨ç±»ä¼¼      
Kohya Deep Shrink     
ScaleCrafter    

https://arxiv.org/abs/2311.17528

[Submitted on 29 Nov 2023 (v1), last revised 29 Apr 2024 (this version, v2)]

HiDiffusion: Unlocking Higher-Resolution Creativity and Efficiency in Pretrained Diffusion Models

æ‰©æ•£æ¨¡å‹å·²æˆä¸ºé«˜åˆ†è¾¨ç‡å›¾åƒåˆæˆçš„ä¸»æµæ–¹æ³•ã€‚ç„¶è€Œï¼Œç›´æ¥ä»é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ç”Ÿæˆæ›´é«˜åˆ†è¾¨ç‡çš„å›¾åƒä¼šé‡åˆ°ä¸åˆç†çš„å¯¹è±¡é‡å¤å¹¶æˆå€å¢åŠ ç”Ÿæˆæ—¶é—´ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å‘ç°å¯¹è±¡é‡å¤æºäº U-Net æ·±å±‚å—ä¸­çš„ç‰¹å¾é‡å¤ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬å°†ç”Ÿæˆæ—¶é—´çš„å»¶é•¿å½’å› äº U-Net é¡¶éƒ¨å—ä¸­çš„è‡ªæ³¨æ„åŠ›å†—ä½™ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ— éœ€è°ƒæ•´çš„é«˜åˆ†è¾¨ç‡æ¡†æ¶ HiDiffusionã€‚å…·ä½“æ¥è¯´ï¼ŒHiDiffusion åŒ…å«åˆ†è¾¨ç‡æ„ŸçŸ¥ U-Net (RAU-Net)ï¼Œå®ƒå¯ä»¥åŠ¨æ€è°ƒæ•´ç‰¹å¾å›¾å¤§å°æ¥è§£å†³å¯¹è±¡é‡å¤é—®é¢˜ï¼Œå¹¶ä½¿ç”¨æ”¹è¿›çš„ç§»ä½çª—å£å¤šå¤´è‡ªæ³¨æ„åŠ› (MSW-MSA)ï¼Œåˆ©ç”¨ä¼˜åŒ–çš„çª—å£æ³¨æ„åŠ›æ¥å‡å°‘è®¡ç®—ã€‚æˆ‘ä»¬å¯ä»¥å°† HiDiffusion é›†æˆåˆ°å„ç§é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ä¸­ï¼Œä»¥å°†å›¾åƒç”Ÿæˆåˆ†è¾¨ç‡æ‰©å±•åˆ° 4096x4096ï¼Œæ¨ç†é€Ÿåº¦æ˜¯ä»¥å‰æ–¹æ³•çš„ 1.5-6 å€ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥è§£å†³å¯¹è±¡é‡å¤å’Œè®¡ç®—é‡å¤§çš„é—®é¢˜ï¼Œåœ¨é«˜åˆ†è¾¨ç‡å›¾åƒåˆæˆä»»åŠ¡ä¸Šå®ç°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚


![alt text](assets/624628/image.png)

## åŸç†

![alt text](assets_picture/624628/image.png)



    def apply_hidiffusion(
            model: torch.nn.Module,
            apply_raunet: bool = True,
            apply_window_attn: bool = True):
        """
        model: diffusers model. We support SD 1.5, 2.1, XL, XL Turbo.
        
        apply_raunet: whether to apply RAU-Net
        
        apply_window_attn: whether to apply MSW-MSA.
        '''
        # Make sure the module is not currently patched
        remove_hidiffusion(model)







Diffusion models have become a mainstream approach for high-resolution image synthesis. However, directly generating higherresolution images from pretrained diffusion models will encounter unreasonable object duplication and exponentially increase the generation time. In this paper, we discover that object duplication arises from feature duplication in the deep blocks of the U-Net. Concurrently, We pinpoint the extended generation times to self-attention redundancy in U-Netâ€™s top blocks. To address these issues, we propose a tuning-free higher-resolution framework named HiDiffusion. Specifically, HiDiffusion contains Resolution-Aware U-Net (RAU-Net) that dynamically adjusts the feature map size to resolve object duplication and engages Modified Shifted Window Multi-head Self-Attention (MSW-MSA) that utilizes optimized window attention to reduce computations. we can integrate HiDiffusion into various pretrained diffusion models to scale image generation resolutions even to 4096Ã—4096 at 1.5-6Ã— the inference speed of previous methods. Extensive experiments demonstrate that our approach can address object duplication and heavy computation issues, achieving state-of-the-art performance on higher-resolution image synthesis tasks.


![alt text](assets_picture/624628/image-1.png)


ä»–è¿™ä¸ªç«Ÿç„¶ä¸ç”¨è®­ç»ƒ ä¸ç”¨æƒé‡ å°±èƒ½è¿™æ ·è¯¥ç»“æ„


å¦‚æœè¯´cutå±äºpatchæ‰¾è§„å¾‹ é‚£è¿™ä¸ªå°±æœ‰ç‚¹ç¡¬æ ¸

![alt text](assets_picture/624628/image-2.png)


![alt text](assets_picture/624628/image-3.png)



![alt text](assets_picture/624628/image-4.png)


![alt text](assets_picture/624628/image-5.png)


![alt text](assets_picture/624628/image-6.png)



## ä»£ç 
çœ‹èµ·æ¥ä¸»è¦æ˜¯æ¢äº†æ¨¡å‹ç»“æ„å»æ¨ç†      
æœ‰ä¸€äº›é˜ˆå€¼


    # T1_ratio: see T1 introduced in the main paper. T1 = number_inference_step * T1_ratio. A higher T1_ratio can better mitigate object duplication. We set T1_ratio=0.4 by default. You'd better adjust it to fit your prompt. Only active when apply_raunet=True.
    # T2_ratio: see T2 introduced in the appendix, used in extreme resolution image generation. T2 = number_inference_step * T2_ratio. A higher T2_ratio can better mitigate object duplication. Only active when apply_raunet=True
    switching_threshold_ratio_dict = {
        'sd15_1024': {'T1_ratio': 0.4, 'T2_ratio': 0.0},
        'sd15_2048': {'T1_ratio': 0.7, 'T2_ratio': 0.3},
        'sdxl_2048': {'T1_ratio': 0.4, 'T2_ratio': 0.0},
        'sdxl_4096': {'T1_ratio': 0.7, 'T2_ratio': 0.3},
        'sdxl_turbo_1024': {'T1_ratio': 0.5, 'T2_ratio': 0.0},
    }

mitigate object duplication.

    is_aggressive_raunet = True
    aggressive_step = 8


    def make_diffusers_cross_attn_down_block(block_class: Type[torch.nn.Module]) -> Type[torch.nn.Module]:
        # replace conventional downsampler with resolution-aware downsampler


    def make_diffusers_downsampler_block(block_class: Type[torch.nn.Module]) -> Type[torch.nn.Module]:
        # replace conventional downsampler with resolution-aware downsampler


ä¹Ÿä½¿ç”¨unpack



    diffusion_model.info = {
        'size': None, 
        'upsample_size': None,
        'hooks': [], 
        'text_to_img_controlnet': hasattr(model, 'controlnet'),
        'is_inpainting_task': 'inpainting' in name_or_path, 
        'is_playground': 'playground' in name_or_path,
        'pipeline': model}
    model.info = diffusion_model.info
    hook_diffusion_model(diffusion_model)



def hook_diffusion_model(model: torch.nn.Module):

    """ Adds a forward pre hook to get the image size. This hook can be removed with remove_hidiffusion. """
    def hook(module, args):
        module.info["size"] = (args[0].shape[2], args[0].shape[3])
        return None

    model.info["hooks"].append(model.register_forward_pre_hook(hook))

argsæ€ä¹ˆæ¥çš„


ä¸»è¦éœ€è¦æ”¹æ¨¡å‹ç»“æ„     
å…¶å®å°±æ˜¯è°ƒç”¨çš„è¾“å…¥è¾“å‡ºåšå˜åŒ–     

ç›´æ¥æ”¹æ¨¡å‹ç»“æ„ä¹Ÿæ–¹ä¾¿äº› å°±æ˜¯å“ªäº›æ­¥æœ‰å“ªç§è¾“å…¥

å¦‚æœæ”¹æ¨¡å‹ç»“æ„å°±æ˜¯è¦æ”¹kdiffusion

éæ–¹å½¢åˆ†è¾¨ç‡ é—®é¢˜è§£å†³åœ¨    

num_upsamplers

cross_attn_up_block

cross_attn_down_block

make_diffusers_transformer_block

å¦‚æœæ”¹èƒ½æ€ä¹ˆæ”¹

script æ€ä¹ˆä¿®æ”¹æ¨¡å‹ç»“æ„      
å…¶å®ä¹Ÿä¸æ˜¯ä¿®æ”¹æ¨¡å‹ç»“æ„     
æ¯ä¸€å°å—çš„è¾“å…¥è¾“å‡ºåšè°ƒæ•´      

èƒ½æ’å…¥å—       
ç»“æŸåéœ€è¦å¤åŸ

ä»¥patchå½¢å¼å—

ä»–è¿™ä¸ªä¸æ˜¯æ”¹é‡‡æ ·å™¨     



    def sdxl_hidiffusion_key():
        modified_key = dict()
        modified_key['down_module_key'] = ['down_blocks.1']
        modified_key['down_module_key_extra'] = ['down_blocks.1.downsamplers.0.conv']
        modified_key['up_module_key'] = ['up_blocks.1']
        modified_key['up_module_key_extra'] = ['up_blocks.0.upsamplers.0.conv']
        modified_key['windown_attn_module_key'] = ['down_blocks.1.attentions.0.transformer_blocks.0', 
        'down_blocks.1.attentions.0.transformer_blocks.1', 
        'down_blocks.1.attentions.1.transformer_blocks.0',
        'down_blocks.1.attentions.1.transformer_blocks.1',
        'up_blocks.1.attentions.0.transformer_blocks.0', 
        'up_blocks.1.attentions.0.transformer_blocks.1',
        'up_blocks.1.attentions.1.transformer_blocks.0', 
        'up_blocks.1.attentions.1.transformer_blocks.1', 
        'up_blocks.1.attentions.2.transformer_blocks.0', 
        'up_blocks.1.attentions.2.transformer_blocks.1']
        
        return modified_key


æ”¹æ¨¡å‹åªèƒ½æ˜¯pacth hookè¿‡å»

å•çº¯scriptæ”¹ä¸äº† æ”¹æ¨¡å‹ä¿å­˜æ¨¡å‹æ˜¾å­˜ä»£ä»·è¿‡å¤§


https://github.com/kijai/ComfyUI-ELLA-wrapper/blob/main/nodes.py

è¿™ä¸ªæ’ä»¶åªæ˜¯

    from diffusers.loaders.single_file_utils import (
            convert_ldm_vae_checkpoint, 
            convert_ldm_unet_checkpoint, 
            create_vae_diffusers_config, 
            create_unet_diffusers_config,
            create_text_encoder_from_ldm_clip_checkpoint
        )         

https://github.com/invoke-ai/InvokeAI/issues/6309

å®ƒçš„å¼€æºä»£ç æ˜¯åŸºäºæ‰©æ•£å™¨çš„ï¼Œå› æ­¤æ·»åŠ æ­¤åŠŸèƒ½ä¸€å®šç›¸å½“å®¹æ˜“ã€‚

æˆ‘ä»¬åœ¨æ‰©æ•£å™¨å‘¨å›´æœ‰å¾ˆå¤šè‡ªå®šä¹‰é€»è¾‘ï¼Œè€Œâ€œåªéœ€æ·»åŠ ä¸€è¡Œï¼â€å¹¶ä¸ä¸€å®šé€‚ç”¨äºæˆ‘ä»¬çš„å®ç°ã€‚

@RyanJDick @lsteinæ‚¨èƒ½å°±å®æ–½è¿™é¡¹åŠŸèƒ½çš„åŠªåŠ›æå‡ºå»ºè®®å—ï¼Ÿå®ƒå°†å–ä»£ HRO åŠŸèƒ½ï¼ˆè‡ªåŠ¨ç¬¬äºŒé img2imgï¼‰ã€‚

TLDRï¼šæˆ‘è®¤ä¸ºHiDiffusion å¯ä»¥ä»¥ä¸æˆ‘ä»¬æ‰€æœ‰å…¶ä»–åŠŸèƒ½å…¼å®¹çš„æ–¹å¼å¾—åˆ°æ”¯æŒã€‚ä½†æ˜¯ï¼Œè¿™è‚¯å®šä¼šæ¯”ä»–ä»¬å®£ä¼ çš„å•è¡Œä»£ç ä»˜å‡ºæ›´å¤šåŠªåŠ›ã€‚æˆ‘ä»¬åº”è¯¥è¿›è¡Œæ›´å¤šæµ‹è¯•ï¼Œä»¥ç¡®ä¿æ­¤åŠŸèƒ½å€¼å¾—å®æ–½/ç»´æŠ¤ï¼ˆè®ºæ–‡ä¸­çš„ç¤ºä¾‹çœ‹èµ·æ¥å¾ˆæ£’ï¼‰ã€‚


HiDiffusion ä»¥ä¸¤ç§æ–¹å¼ä¿®æ”¹äº† UNetï¼šRAU-Netï¼ˆåˆ†è¾¨ç‡æ„ŸçŸ¥ U-Netï¼‰å’Œ MSW-MSAï¼ˆæ”¹è¿›çš„ç§»ä½çª—å£å¤šå¤´è‡ªæ³¨æ„åŠ›ï¼‰ã€‚è¿™äº›éƒ½æ˜¯å¯¹ UNet çš„æ— éœ€è°ƒæ•´çš„ä¿®æ”¹ï¼Œå³ä¸éœ€è¦æ–°çš„æƒé‡ã€‚

RAU-Net æ—¨åœ¨é¿å…é«˜åˆ†è¾¨ç‡ä¸‹çš„ä¸»é¢˜é‡å¤ã€‚å®ƒé€šè¿‡æ”¹å˜ UNet å±‚çš„ä¸‹é‡‡æ ·/ä¸Šé‡‡æ ·æ¨¡å¼æ¥å®ç°è¿™ä¸€ç‚¹ï¼Œè¿™æ ·æ·±å±‚å°±å¯ä»¥ä»¥æ›´æ¥è¿‘å…¶è®­ç»ƒæ—¶çš„åˆ†è¾¨ç‡è¿è¡Œã€‚     
æ ¸å¿ƒè¿˜æ˜¯è¿™ä¸ªä¸œè¥¿    


MSW-MSA ä¿®æ”¹é€šè¿‡å¯¹é¡¶éƒ¨ UNet å—çš„è‡ªæ³¨æ„å±‚åº”ç”¨çª—å£æ¥æ”¹å–„é«˜åˆ†è¾¨ç‡çš„ç”Ÿæˆæ—¶é—´ã€‚


A lot of code in RAU-Net are directly copied from diffusers impl (That is why I do not like diffuers). The main logic seem to be further increase compression / decompression by 2.


å¯¹çš„ã€‚ä»æˆ‘å¼„æ˜ç™½çš„æƒ…å†µæ¥çœ‹ï¼Œé™¤äº† MSW-MSA æ³¨æ„éƒ¨åˆ†ä¹‹å¤–ï¼Œå®ƒå‡ ä¹ä¸ Kohya Deep Shrink å®Œå…¨ä¸€æ ·ã€‚

äº¤å‰æ³¨æ„éƒ¨åˆ†ä½¿ç”¨ Torchavg_pool2dè€Œä¸æ˜¯åŒä¸‰æ¬¡ã€‚
RAU é™é‡‡æ ·å™¨éƒ¨åˆ†ä½¿ç”¨è½¬æ¢æ­¥å¹…/æ‰©å¼ æ¥ç¼©å°è§„æ¨¡ï¼Œè€Œä¸æ˜¯åŒä¸‰æ¬¡ã€‚

å¯¹äºç¬¬äºŒä¸ªï¼Œç¼©å°å‘ç”Ÿçš„ä½ç½®å¯èƒ½å¾ˆé‡è¦ã€‚è½¬æ¢æ–¹æ³•ç¡®å®ä¼¼ä¹æ¯”æ·±åº¦ç¼©å°äº§ç”Ÿæ›´å¥½çš„ç»“æœï¼ˆåŒ…æ‹¬æˆ‘å°è¯•è¿‡çš„å…¶ä»–ç¼©å°æ–¹æ³•ï¼‰ã€‚

æ®æˆ‘æ‰€çŸ¥ï¼ŒRAU-Net éƒ¨åˆ†æœ¬è´¨ä¸Šæ˜¯ Kohya Deep Shrinkï¼ˆåˆåPatchModelAddDownscaleï¼‰ï¼šå…¶æ¦‚å¿µæ˜¯åœ¨ç”Ÿæˆå¼€å§‹æ—¶ç¼©å°å›¾åƒï¼Œè®©æ¨¡å‹è®¾ç½®ä¸»è¦ç»†èŠ‚ï¼Œä¾‹å¦‚è§’è‰²æœ‰å¤šå°‘æ¡è…¿ï¼Œç„¶åå…è®¸æ¨¡å‹åœ¨ç¼©æ”¾æ•ˆæœç»“æŸåç»†åŒ–å’Œæ·»åŠ ç»†èŠ‚ã€‚è¯¥éƒ¨åˆ†çš„ä¸»è¦åŒºåˆ«åœ¨äºç¼©å°æ–¹æ³• - å®ƒä½¿ç”¨å·ç§¯ä¸æ­¥å¹…/æ‰©å¼ å’Œæ± å¹³å‡æ¥ç¼©å°å°ºå¯¸ï¼Œè€Œ Deep Shrink é€šå¸¸ä½¿ç”¨åŒä¸‰æ¬¡ç¼©å°å°ºå¯¸ã€‚ç¼©æ”¾å‘ç”Ÿçš„ä½ç½®ä¹Ÿå¯èƒ½å¾ˆé‡è¦ - å®ƒä¼¼ä¹ç¡®å®æ¯” Deep Shrink æ•ˆæœå¥½å¾—å¤šï¼Œè‡³å°‘å¯¹äº SD 1.5 æ¥è¯´æ˜¯è¿™æ ·ã€‚



    def process(self, p, enable, only_one_pass, d1, d2, s1, s2, scaler, downscale, upscale, smooth_scaling, early_out):
        self.config = DictConfig({name: var for name, var in locals().items() if name not in ['self', 'p']})
        if not enable or self.disable:
            script_callbacks.remove_current_script_callbacks()
            return
        model = p.sd_model.model.diffusion_model
        if s1 > s2: self.config.s2 = s1
        self.p1 = (s1, d1 - 1)
        self.p2 = (s2, d2 - 1)
        self.step_limit = 0
        
        def denoiser_callback(params: script_callbacks.CFGDenoiserParams):
            if params.sampling_step < self.step_limit: return
            for s, d in [self.p1, self.p2]:
                out_d = d if self.config.early_out else -(d + 1)
                if params.sampling_step < params.total_sampling_steps * s:
                    if not isinstance(model.input_blocks[d], Scaler):
                        model.input_blocks[d] = Scaler(self.config.downscale, model.input_blocks[d], self.config.scaler)
                        model.output_blocks[out_d] = Scaler(self.config.upscale, model.output_blocks[out_d], self.config.scaler)
                    elif self.config.smooth_scaling:
                        scale_ratio = params.sampling_step / (params.total_sampling_steps * s)
                        downscale = min((1 - self.config.downscale) * scale_ratio + self.config.downscale, 1.0)
                        model.input_blocks[d].scale = downscale
                        model.output_blocks[out_d].scale = self.config.upscale * (self.config.downscale / downscale)
                    return
                elif isinstance(model.input_blocks[d], Scaler) and (self.p1[1] != self.p2[1] or s == self.p2[0]):
                    model.input_blocks[d] = model.input_blocks[d].block
                    model.output_blocks[out_d] = model.output_blocks[out_d].block
            self.step_limit = params.sampling_step if self.config.only_one_pass else 0

        script_callbacks.on_cfg_denoiser(denoiser_callback)



è¿™ä¸ªç›´æ¥æ”¹cfg denoiseræ„Ÿè§‰å—ç‰ˆæœ¬å½±å“å¤§


    æ£€æŸ¥å½“å‰é‡‡æ ·æ­¥éª¤æ˜¯å¦è¾¾åˆ°å¤„ç†æ¡ä»¶ã€‚
    æ ¹æ®æ¡ä»¶å¯¹æ¨¡å‹çš„è¾“å…¥å’Œè¾“å‡ºå—è¿›è¡Œç¼©æ”¾å¤„ç†ã€‚
    å¦‚æœå¯ç”¨å¹³æ»‘ç¼©æ”¾ï¼Œä¼šæ ¹æ®å½“å‰æ­¥éª¤åŠ¨æ€è°ƒæ•´ç¼©æ”¾æ¯”ä¾‹ã€‚
    åœ¨ç‰¹å®šæ¡ä»¶ä¸‹ï¼Œæ¢å¤åŸå§‹çš„è¾“å…¥å’Œè¾“å‡ºå—ã€‚

æ³¨å†Œå›è°ƒ:   
pythonCopyscript_callbacks.on_cfg_denoiser(denoiser_callback)     
å°†å®šä¹‰çš„å›è°ƒå‡½æ•°æ³¨å†Œåˆ°å»å™ªå™¨ä¸­ã€‚

è¿™æ®µä»£ç çš„ä¸»è¦ç›®çš„ä¼¼ä¹æ˜¯åœ¨å›¾åƒç”Ÿæˆæˆ–å¤„ç†è¿‡ç¨‹ä¸­ï¼Œæ ¹æ®ä¸åŒçš„é‡‡æ ·é˜¶æ®µåŠ¨æ€è°ƒæ•´æ¨¡å‹çš„æŸäº›å±‚çš„ç¼©æ”¾è¡Œä¸ºã€‚è¿™å¯èƒ½ç”¨äºæé«˜ç”Ÿæˆè´¨é‡æˆ–ä¼˜åŒ–å¤„ç†æ•ˆç‡ã€‚


    æ­¥éª¤é™åˆ¶æ£€æŸ¥ï¼š
    pythonCopyif params.sampling_step < self.step_limit: return
    å¦‚æœå½“å‰é‡‡æ ·æ­¥éª¤å°äº step_limitï¼Œå‡½æ•°ç›´æ¥è¿”å›ã€‚è¿™å¯èƒ½æ˜¯ä¸ºäº†é¿å…é‡å¤å¤„ç†æˆ–é™åˆ¶å¤„ç†é¢‘ç‡ã€‚
    ä¸»å¾ªç¯ï¼š
    pythonCopyfor s, d in [self.p1, self.p2]:
    è¿™ä¸ªå¾ªç¯éå†ä¸¤ç»„å‚æ•° p1 å’Œ p2ï¼Œå®ƒä»¬åˆ†åˆ«ä»£è¡¨ä¸åŒçš„å¤„ç†é˜¶æ®µæˆ–æ¡ä»¶ã€‚

    è¾“å‡ºå±‚ç´¢å¼•è®¡ç®—ï¼š
    pythonCopyout_d = d if self.config.early_out else -(d + 1)
    æ ¹æ®æ˜¯å¦å¯ç”¨ early_outï¼Œè®¡ç®—è¾“å‡ºå±‚çš„ç´¢å¼•ã€‚
    ä¸»è¦å¤„ç†é€»è¾‘ï¼š
    pythonCopyif params.sampling_step < params.total_sampling_steps * s:
    è¿™ä¸ªæ¡ä»¶æ£€æŸ¥å½“å‰æ˜¯å¦å¤„äºéœ€è¦è¿›è¡Œç¼©æ”¾å¤„ç†çš„é‡‡æ ·é˜¶æ®µã€‚
    ç¼©æ”¾å™¨æ›¿æ¢ï¼š
    pythonCopyif not isinstance(model.input_blocks[d], Scaler):
        model.input_blocks[d] = Scaler(self.config.downscale, model.input_blocks[d], self.config.scaler)
        model.output_blocks[out_d] = Scaler(self.config.upscale, model.output_blocks[out_d], self.config.scaler)
    å¦‚æœå½“å‰è¾“å…¥å—ä¸æ˜¯ Scaler ç±»å‹ï¼Œåˆ™ç”¨ Scaler å¯¹è±¡æ›¿æ¢è¾“å…¥å’Œè¾“å‡ºå—ã€‚è¿™å®ç°äº†åŠ¨æ€ç¼©æ”¾åŠŸèƒ½ã€‚


    å¹³æ»‘ç¼©æ”¾ï¼š
    pythonCopyelif self.config.smooth_scaling:
        scale_ratio = params.sampling_step / (params.total_sampling_steps * s)
        downscale = min((1 - self.config.downscale) * scale_ratio + self.config.downscale, 1.0)
        model.input_blocks[d].scale = downscale
        model.output_blocks[out_d].scale = self.config.upscale * (self.config.downscale / downscale)
    å¦‚æœå¯ç”¨äº†å¹³æ»‘ç¼©æ”¾ï¼Œæ ¹æ®å½“å‰æ­¥éª¤åŠ¨æ€è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼Œå¹¶åº”ç”¨åˆ°è¾“å…¥å’Œè¾“å‡ºå—ã€‚
    æ¢å¤åŸå§‹å—ï¼š
    pythonCopyelif isinstance(model.input_blocks[d], Scaler) and (self.p1[1] != self.p2[1] or s == self.p2[0]):
        model.input_blocks[d] = model.input_blocks[d].block
        model.output_blocks[out_d] = model.output_blocks[out_d].block
    åœ¨ç‰¹å®šæ¡ä»¶ä¸‹ï¼ˆæ¯”å¦‚å¤„ç†é˜¶æ®µç»“æŸï¼‰ï¼Œå°†è¢« Scaler æ›¿æ¢çš„å—æ¢å¤ä¸ºåŸå§‹å—ã€‚

    æ›´æ–°æ­¥éª¤é™åˆ¶ï¼š
    pythonCopyself.step_limit = params.sampling_step if self.config.only_one_pass else 0
    å¦‚æœé…ç½®ä¸ºåªå¤„ç†ä¸€æ¬¡ï¼Œæ›´æ–° step_limit ä»¥é˜²æ­¢é‡å¤å¤„ç†ã€‚



éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™ä¸ªå‡½æ•°å‡è®¾æ¨¡å‹ç»“æ„ä¸­æœ‰ input_blocks å’Œ output_blocksï¼Œå¹¶ä¸”å¯ä»¥åŠ¨æ€æ›¿æ¢è¿™äº›å—çš„å®ç°ã€‚è¿™è¡¨æ˜å®ƒå¯èƒ½æ˜¯é’ˆå¯¹ç‰¹å®šç±»å‹çš„ç”Ÿæˆæ¨¡å‹ï¼ˆå¦‚æŸäº›æ‰©æ•£æ¨¡å‹ï¼‰è®¾è®¡çš„ã€‚



    class Scaler(torch.nn.Module):
        def __init__(self, scale, block, scaler):
            super().__init__()
            self.scale = scale
            self.block = block
            self.scaler = scaler
            
        def forward(self, x, *args):
            x = torch.nn.functional.interpolate(x, scale_factor=self.scale, mode=self.scaler)
            return self.block(x, *args)

å…ˆç¼©æ”¾ å†è¿›å…¥æ¨¡å—ï¼Ÿï¼Ÿ


è¿™ä¸ª Scaler ç±»çš„ä¸»è¦ç›®çš„æ˜¯åœ¨ç¥ç»ç½‘ç»œçš„æŸä¸ªå—ä¹‹å‰æ·»åŠ ä¸€ä¸ªç¼©æ”¾æ“ä½œã€‚å®ƒå¯ä»¥ç”¨æ¥è°ƒæ•´ç‰¹å¾å›¾çš„å¤§å°ï¼Œå¯èƒ½ç”¨äºä¸Šé‡‡æ ·æˆ–ä¸‹é‡‡æ ·ã€‚
ä½¿ç”¨è¿™ä¸ªç±»çš„å¥½å¤„åŒ…æ‹¬ï¼š

çµæ´»æ€§ï¼šå¯ä»¥è½»æ¾åœ°åœ¨ç½‘ç»œçš„ä»»ä½•éƒ¨åˆ†æ·»åŠ ç¼©æ”¾æ“ä½œã€‚
å¯é…ç½®ï¼šç¼©æ”¾å› å­å’Œæ–¹æ³•å¯ä»¥åœ¨åˆå§‹åŒ–æ—¶æŒ‡å®šã€‚
é€æ˜æ€§ï¼šåŸå§‹çš„ç½‘ç»œå—ä»ç„¶è¢«ä¿ç•™å’Œä½¿ç”¨ã€‚

åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™ä¸ª Scaler ç±»å¯èƒ½è¢«ç”¨äºåŠ¨æ€è°ƒæ•´ç½‘ç»œæŸäº›å±‚çš„è¾“å…¥å¤§å°ï¼Œè¿™åœ¨å›¾åƒç”Ÿæˆæˆ–å¤„ç†ä»»åŠ¡ä¸­å¯èƒ½å¾ˆæœ‰ç”¨ï¼Œä¾‹å¦‚åœ¨ä¸åŒåˆ†è¾¨ç‡ä¸‹ä¿æŒæˆ–è°ƒæ•´ç‰¹å¾çš„è¡¨ç¤ºã€‚


    åˆå§‹åŒ–æ–¹æ³•ï¼š
    pythonCopydef __init__(self, scale, block, scaler):
        super().__init__()
        self.scale = scale
        self.block = block
        self.scaler = scaler

scale: ç¼©æ”¾å› å­
block: è¦åŒ…è£…çš„åŸå§‹ç¥ç»ç½‘ç»œå—
scaler: ç¼©æ”¾æ–¹æ³•ï¼ˆå¦‚ 'bilinear', 'nearest' ç­‰ï¼‰



ç›´æ¥æ›¿æ¢BLOCK

class Scaler(torch.nn.Module):

è¿™é‡Œé¢ä¿å­˜äº†å±æ€§ä¸€ä¸ªblock


æˆ–è€…åƒ cnä¸€æ ·hijack??      
cnæ˜¯å¤§å±‚æ”¹å˜è¾“å…¥

hidiffusionå…¶å®å°±æ˜¯å‹ç¼©æ–¹å¼æ”¹å˜äº† æ•°æ®çš„å‹ç¼©æ–¹å¼      


å…ˆå°è¯•åªå®ç°raunet















# onediff
è½¯è¿å¤±è´¥

ln: failed to create symbolic link '/m': Function not implemented

æœªçŸ¥åŸå› é”™è¯¯

mntå†…

teamå†…

teamåˆ°mntéƒ½ä¸è¡Œ

mntåˆ°teamsä¹Ÿä¸è¡Œ



åœ¨Linuxå‘½ä»¤è¡Œä¸­ï¼Œå¯ä»¥ä½¿ç”¨ find å‘½ä»¤æ¥æœç´¢ä¸€ä¸ªæ–‡ä»¶å¤¹å†…çš„æ‰€æœ‰è½¯è¿æ¥ã€‚ä¸‹é¢æ˜¯å…·ä½“çš„å‘½ä»¤ï¼š

    bash
    å¤åˆ¶ä»£ç 
    find /path/to/directory -type l



ç›´æ¥ä¸è½¯è¿æ¥    
å¤åˆ¶è¿‡å»    
ä½†æ˜¯å¥½åƒæ²¡æœ‰è¿è¡Œinstall.py

æ‰‹è£… pip install git+https://github.com/siliconflow/onediff.git

Successfully installed onediff-1.2.0.dev1

å¯ä»¥äº†

ä½†æ˜¯æˆ‘åœ¨1åŒº 5åŒºéƒ½æ²¡æœ‰çœ‹è§è½¯è¿æ¥

æ¨ç†æŠ¥é”™

æ‰‹è£…

pip install --pre oneflow -f https://oneflow-pro.oss-cn-beijing.aliyuncs.com/branch/community/cu118


oneflowå·²ç»è¢«é˜¿é‡Œæ”¶è´­

å†å»ºonediff

Collecting oneflow    
Downloading https://oneflow-pro.oss-cn-beijing.aliyuncs.com/branch/community/cu118/ec7b682e30831cc0eb30d7cc07d4dcb366c588cd/oneflow-0.9.1.dev20240703%2Bcu118-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1422.5 MB)

Collecting nvidia-cudnn-cu11 (from oneflow)
  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/40/8e/111f88f108cbad7b8fd293fdeb2a7a251205feb48adb504c6caecd0e20e3/nvidia_cudnn_cu11-9.2.0.82-py3-none-manylinux2014_x86_64.whl (572.1 MB)

Collecting nvidia-cublas-cu11 (from oneflow)
  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/46/be/c222e33e60d28ecd496a46fc4d78ccae0ee28e1fd7dc705b6288b4cad27e/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)



Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cudnn-cu11-9.2.0.82 nvidia-cufft-cu11-10.9.0.58 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 oneflow-0.9.1.dev20240703+cu118


è½¯è¿åªå­˜åœ¨äºæœåŠ¡å¯åŠ¨




















# cfg++

https://github.com/invoke-ai/InvokeAI/issues/6516    
ä¸¤å‘¨å‰åˆ°å››å¤©å‰

https://github.com/invoke-ai/InvokeAI/pull/4335     
Nov 30, 2023    
cfg rescale å·²ç»merge


https://github.com/dunkeroni/InvokeAI_ModularDenoiseNodes


https://gitlab.com/keturn/invert_denoise_invoke/-/tree/invoke-v3.5






CFG++ ä¸ CFG Rescale ä¸€æ ·ï¼Œè¯•å›¾è§£å†³çº¿æ€§æ— åˆ†ç±»å™¨å¼•å¯¼å‡½æ•°å®¹æ˜“äº§ç”Ÿåˆ†å¸ƒå¤–å€¼çš„æ–¹å¼ã€‚

CFG++, like CFG Rescale, is an attempt to address the way the linear Classifier-Free Guidance function is prone to producing out-of-distribution values.


æ®æˆ‘äº†è§£ï¼Œæ•°å­¦å¾ˆç®€å•ã€‚ä½†å®ƒä»¥ä¸€ç§å¯æ€•çš„æ–¹å¼ä¸è°ƒåº¦å™¨åœ¨æ‰©æ•£å™¨ä¸­çš„æŠ½è±¡æ–¹å¼ï¼ˆä»¥åŠ Invokeï¼‰å‘ç”Ÿå†²çªã€‚æˆ‘å·²ç»åˆ›å»ºäº†è¿™ä¸ªé—®é¢˜ï¼Œæ‰€ä»¥æœ‰ä¸€ä¸ªåœ°æ–¹å¯ä»¥è®°å½•å®ƒã€‚

But it clashes in an awful way with how Schedulers are abstracted in diffusers (and thus Invoke). I've created this issue so there's a place to keep notes about that.


Invoke åŸºäº diffusersæ„å»ºï¼Ÿ?


æ— åˆ†ç±»å™¨å¼•å¯¼ (CFG)æ˜¯ç°ä»£æ‰©æ•£æ¨¡å‹ä¸­ç”¨äºæ–‡æœ¬å¼•å¯¼ç”Ÿæˆçš„åŸºæœ¬å·¥å…·ã€‚å°½ç®¡ CFG å¾ˆæœ‰æ•ˆï¼Œä½†å®ƒéœ€è¦è¾ƒé«˜çš„å¼•å¯¼è§„æ¨¡ï¼Œè¿™æœ‰æ˜æ˜¾çš„ç¼ºç‚¹ï¼š

æ¨¡å¼å´©æºƒå’Œé¥±å’Œ
å¯é€†æ€§è¾ƒå·®
ä¸è‡ªç„¶ã€å¼¯æ›²çš„ PF-ODE è½¨è¿¹



æˆ‘ä»¬é’ˆå¯¹è¿™ä¸ªçœ‹ä¼¼å›ºæœ‰çš„é™åˆ¶æå‡ºäº†ä¸€ä¸ªç®€å•çš„è§£å†³æ–¹æ¡ˆï¼Œå¹¶æå‡ºäº† CFG++ï¼Œå®ƒçº æ­£äº† CFG çš„æµå½¢å¤–é—®é¢˜ã€‚è§‚å¯Ÿåˆ°ä»¥ä¸‹ä¼˜ç‚¹

![alt text](assets/624628/image-1.png)

æ ·æœ¬è´¨é‡æ›´å¥½ï¼Œæ›´ç¬¦åˆåŸæ–‡è¦æ±‚
æ›´å¹³æ»‘ã€æ›´ç›´çš„ PF-ODE è½¨è¿¹
å¢å¼ºå¯é€†æ€§

å®éªŒç»“æœè¯å®ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—æé«˜äº†æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€DDIM åè½¬ã€ç¼–è¾‘å’Œè§£å†³é€†é—®é¢˜çš„æ€§èƒ½ï¼Œè¡¨æ˜åœ¨åˆ©ç”¨æ–‡æœ¬æŒ‡å¯¼çš„å„ä¸ªé¢†åŸŸå…·æœ‰å¹¿æ³›çš„å½±å“å’Œæ½œåœ¨çš„åº”ç”¨ã€‚


> [!note]
> This work is currently in the preprint stage, and there may be some changes to the code.


è¿™åº”è¯¥æ˜¯ä¸€ä¸ªå¤±è´¥é¡¹ç›®

CFG++: Manifold-constrained Classifier Free Guidance For Diffusion Models
Hyungjin Chung*, Jeongsol Kim*, Geon Yeong Park*, Hyelin Nam*, Jong Chul Ye
KAIST


![alt text](assets/624628/image-2.png)



å®˜æ–¹ä»…æœ‰ddimæ”¯æŒ

image edit è®ºæ–‡ä¸Šçœ‹èµ·æ¥æ•ˆæœæ¯”è¾ƒå¥½

æ–‡ç”Ÿå›¾æ¯”è¾ƒä¸ç¨³å®š

editå¦‚ä½•ç”¨ï¼Ÿ


# Be-Your-Outpainter 
è€—æ—¶å››ä¸ªæœˆå¼€æº

https://github.com/G-U-N/Be-Your-Outpainter 


![alt text](assets/624628/image-4.png)


è®­ç»ƒ17386MB
æ¯ä¸ªè§†é¢‘åŸºäºé¢„è®­ç»ƒloraå†è®­ç»ƒ800æ­¥ lora   
æ¨ç†9496mb

800æ­¥ è€—æ—¶ 20åˆ†é’Ÿ



# MultiDiffusion

æ–¹æ³•

æˆ‘ä»¬çš„ä¸»è¦æ€æƒ³æ˜¯åœ¨é¢„å…ˆè®­ç»ƒçš„å‚è€ƒæ‰©æ•£æ¨¡å‹ä¸Šå®šä¹‰ä¸€ä¸ªæ–°çš„ç”Ÿæˆè¿‡ç¨‹ã€‚ä»å™ªå£°å›¾åƒå¼€å§‹ï¼Œåœ¨æ¯ä¸ªç”Ÿæˆæ­¥éª¤ä¸­ï¼Œæˆ‘ä»¬è§£å†³ä¸€ä¸ªä¼˜åŒ–ä»»åŠ¡ï¼Œå…¶ç›®æ ‡æ˜¯ä½¿æ¯ä¸ªè£å‰ªå›¾åƒå°½å¯èƒ½æ¥è¿‘å…¶å»å™ªç‰ˆæœ¬ã€‚

![alt text](assets/624628/image-3.png)


è¯·æ³¨æ„ï¼Œè™½ç„¶æ¯ä¸ªå»å™ªæ­¥éª¤å¯èƒ½ä¼šæ‹‰å‘ä¸åŒçš„æ–¹å‘ï¼Œä½†æˆ‘ä»¬çš„æµç¨‹å°†è¿™äº›ä¸ä¸€è‡´çš„æ–¹å‘èåˆåˆ°å…¨å±€å»å™ªæ­¥éª¤ä¸­ï¼Œä»è€Œäº§ç”Ÿé«˜è´¨é‡çš„æ— ç¼å›¾åƒã€‚


æ„Ÿè§‰è¿™ä¸ªç”¨æ¥outpaintä¼šæ¯”ä¼ ç»Ÿå¥½ä¸€äº›




# ç»“å°¾